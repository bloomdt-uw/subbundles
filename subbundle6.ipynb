{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subbundles Part 6: Visualization\n",
    "\n",
    "**Subbundle** - a subgroup of streamlines with a set of common properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import os.path as op\n",
    "\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from dipy.io.streamline import load_tractogram\n",
    "from dipy.io.stateful_tractogram import StatefulTractogram\n",
    "from dipy.stats.analysis import afq_profile, gaussian_weights\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dipy.viz import window, actor\n",
    "from IPython.display import Image\n",
    "\n",
    "from AFQ import api\n",
    "import AFQ.data as afd\n",
    "\n",
    "from AFQ.viz.fury_backend import visualize_volume\n",
    "from AFQ.viz.fury_backend import visualize_bundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlines (from Part 2)\n",
    "\n",
    "<span style=\"color:blue\">**TODO: add test retest comparision**</span>. This will be in notebook 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'HCP'\n",
    "# dataset_name = 'HCP_retest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = get_subjects(dataset_name)\n",
    "subjects = get_subjects_small(dataset_name)\n",
    "# subjects = get_subjects_medium(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myafq = get_afq(dataset_name)\n",
    "display(myafq.data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle_names = [*myafq.bundle_dict]\n",
    "# bundle_names = ['SLF_L', 'SLF_R']\n",
    "# bundle_names = ['ARC_L', 'ARC_R', 'CST_L', 'CST_R', 'FP'] \n",
    "# bundle_names = ['SLF_L', 'SLF_R', 'ARC_L', 'ARC_R', 'CST_L', 'CST_R', 'FP']\n",
    "bundle_names = ['SLF_L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    target_dirs[subject] = {}\n",
    "    \n",
    "    loc = get_iloc(myafq, subject)\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        target_dir = get_dir_name(myafq, dataset_name, bundle_name, loc)\n",
    "        target_dirs[subject][bundle_name] = target_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_fnames = {}\n",
    "tractograms = {}\n",
    "streamlines = {}\n",
    "affines = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    tg_fnames[subject] = {}\n",
    "    tractograms[subject] = {}\n",
    "    streamlines[subject] = {}\n",
    "    affines[subject] = {}\n",
    "    \n",
    "    loc = get_iloc(myafq, subject)\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        tg_fnames[subject][bundle_name] = get_tractogram_filename(myafq, bundle_name, loc)\n",
    "        tractograms[subject][bundle_name] = load_tractogram(tg_fnames[subject][bundle_name], 'same')\n",
    "        streamlines[subject][bundle_name] = tractograms[subject][bundle_name].streamlines\n",
    "        affines[subject][bundle_name] = tractograms[subject][bundle_name].affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters (from Part 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['sc']\n",
    "model_names = ['sc', 'gmm', 'ms', 'hier']\n",
    "\n",
    "idxs = {}\n",
    "labels = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    idxs[subject] = {}\n",
    "    labels[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        idxs[subject][bundle_name] = []\n",
    "        labels[subject][bundle_name] = []\n",
    "        target_dir = target_dirs[subject][bundle_name]\n",
    "#         adjacencies_names = ['fa', 'r2', 'md', 'wt', 'mdf']\n",
    "#         adjacencies_names = get_adjacencies_names(target_dir, '*wt*pairwise*')\n",
    "        adjacencies_names = get_adjacencies_names(target_dir)\n",
    "\n",
    "        for adjacency_name in adjacencies_names:\n",
    "            for model_name in model_names:\n",
    "                label = f'{model_name}_{adjacency_name}'\n",
    "                labels[subject][bundle_name].append(label)\n",
    "                idx = np.load(op.join(target_dir, f'{label}_idx.npy'))\n",
    "                idxs[subject][bundle_name].append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Switching\n",
    "\n",
    "Change order of clusters from largest to smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resort_cluster_ids(idx):\n",
    "    from_values = np.flip(np.argsort(np.bincount(idx))[-(np.unique(idx).size):])\n",
    "    to_values = np.arange(from_values.size)\n",
    "    d = dict(zip(from_values, to_values))\n",
    "    new_idx = np.copy(idx)\n",
    "    for k, v in d.items(): new_idx[idx==k] = v\n",
    "    return new_idx        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        resorted_idxs = []\n",
    "\n",
    "        for idx in idxs[subject][bundle_name]:\n",
    "            resorted_idxs.append(resort_cluster_ids(idx))\n",
    "    \n",
    "            idxs[subject][bundle_name] = resorted_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subselect models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if False:\n",
    "    import re\n",
    "\n",
    "    for subject in subjects:\n",
    "        for bundle_name in bundle_names:\n",
    "#             models = [model_name.startswith('sc_wt') for model_name in labels[subject][bundle_name]]\n",
    "            models = [bool(re.match(r'^sc_wt.*warped.*', model_name)) for model_name in labels[subject][bundle_name]]\n",
    "            labels[subject][bundle_name] = np.array(labels)[models]\n",
    "            idxs[subject][bundle_name] = np.array(idxs)[models]\n",
    "            print(labels[subject][bundle_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# hardcoding\n",
    "# TODO for each model find out the number of clusters\n",
    "_bundle_labels = [[label] * 3 for label in labels]\n",
    "bundle_labels = []\n",
    "ii=0\n",
    "for sublist in _bundle_labels:\n",
    "    for i in sublist:\n",
    "        bundle_labels.append(i + ' ' + str(ii))\n",
    "        ii +=1\n",
    "    ii=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_labels = {}\n",
    "for subject in subjects:\n",
    "    bundle_labels[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        bundle_labels[subject][bundle_name] = []\n",
    "        for idx, label in zip(idxs[subject][bundle_name], labels[subject][bundle_name]):\n",
    "            for cluster_id in np.unique(idx):\n",
    "                bundle_labels[subject][bundle_name].append(label + ' ' + str(cluster_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bundle_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Clustered Streamline Indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids = {}\n",
    "clusters = {}\n",
    "clusters_cnts = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    cluster_ids[subject] = {}\n",
    "    clusters[subject] = {}\n",
    "    clusters_cnts[subject] = {}\n",
    "    \n",
    "    for bundle_name in bundle_names:\n",
    "        cluster_ids[subject][bundle_name] = []\n",
    "        clusters[subject][bundle_name] = []\n",
    "        clusters_cnts[subject][bundle_name] = {}\n",
    "        \n",
    "        for idx, label in zip(idxs[subject][bundle_name], labels[subject][bundle_name]):\n",
    "            cluster_id = np.unique(idx)\n",
    "            cluster_ids[subject][bundle_name].append(cluster_id)\n",
    "            \n",
    "            # per cluster streamline indicies\n",
    "            cluster = np.array([np.where(idx == i)[0] for i in cluster_id])\n",
    "            clusters[subject][bundle_name].append(cluster)\n",
    "            \n",
    "#             print(f\"{subject} {bundle_name} {label} streamlines per cluster:\", np.bincount(idx))\n",
    "            clusters_cnts[subject][bundle_name][label] = np.bincount(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(cluster_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts_df = pd.DataFrame(clusters_cnts)\n",
    "display(cnts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if len(cnts_df.loc[bundle_name][subject].items()) > 0:\n",
    "            for model_name in model_names:\n",
    "                my_dict = {k: v for k,v in cnts_df.loc[bundle_name][subject].items() if k.startswith(model_name)}\n",
    "                my_df = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "                my_df.T.plot(kind='bar', legend=None, color='tab:blue', title=f'{dataset_name} {subject} {bundle_name}\\n {model_name} cluster counts')\n",
    "                plt.show()\n",
    "                display(my_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**TODO: find streamline changes between models**</span>\n",
    "- Select subject\n",
    "- Select bundle\n",
    "- Select models\n",
    "- Compare each cluster\n",
    "- Find differences\n",
    "- Plot streamines, streamline profiles, subbundle profiles...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Evaluation: ARI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ARI_scores = [[adjusted_rand_score(a,b) for a in idxs] for b in idxs]\n",
    "\n",
    "if (big_plots):\n",
    "    plt.figure(figsize = (len(idxs),len(idxs)))\n",
    "    plt.title('ARI scores')\n",
    "    plt.imshow(ARI_scores, cmap='hot', interpolation='nearest')\n",
    "    for (i, j), z in np.ndenumerate(ARI_scores):\n",
    "        plt.text(j, i, '{:0.2f}'.format(z), ha='center', va='center',\n",
    "                 bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(idxs)), labels, rotation=90)\n",
    "    plt.yticks(np.arange(len(idxs)), labels)\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.figure()\n",
    "    plt.title('ARI scores')\n",
    "    plt.imshow(ARI_scores, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 5\n",
    "j = 10\n",
    "\n",
    "plt.figure()\n",
    "plt.title('streamline classification')\n",
    "plt.bar(np.arange(len(idxs[i])),idxs[i])\n",
    "plt.bar(np.arange(len(idxs[j])),idxs[j])\n",
    "plt.legend([labels[i], labels[j]])\n",
    "plt.yticks(np.arange(np.maximum(np.max(idxs[i]),np.max(idxs[j]))+1))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('classification frequency')\n",
    "plt.hist([idxs[i], idxs[j]], label=[labels[i], labels[j]])\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(np.maximum(np.max(idxs[i]),np.max(idxs[j]))+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice's Coeeficient\n",
    "\n",
    "Twice the area of overlap divided by the sum of both areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import dice\n",
    "\n",
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        for model_name in model_names:\n",
    "\n",
    "            # select a subset of models\n",
    "            my_models = []\n",
    "            num_clusters = 0\n",
    "\n",
    "            for ids, label in zip(cluster_ids[subject][bundle_name], labels[subject][bundle_name]):\n",
    "                if model_name in label and 'pairwise_warped' in label and 'mdf' in label:\n",
    "                    my_models.append(label)\n",
    "                    num_clusters += len(ids)\n",
    "            \n",
    "            dice_matrix = np.zeros((num_clusters, num_clusters))\n",
    "\n",
    "            ii=0\n",
    "            jj=0\n",
    "\n",
    "            for ids1, idx1, label1 in zip(cluster_ids[subject][bundle_name], clusters[subject][bundle_name], labels[subject][bundle_name]):\n",
    "                if label1 not in my_models:\n",
    "                    continue\n",
    "\n",
    "                for i in ids1:\n",
    "                    bundle1 = np.zeros(len(streamlines[subject][bundle_name]))\n",
    "                    bundle1[idx1[i]] = 1\n",
    "\n",
    "                    for ids2, idx2, label2 in zip(cluster_ids[subject][bundle_name], clusters[subject][bundle_name], labels[subject][bundle_name]):\n",
    "                        if label2 not in my_models:\n",
    "                            continue\n",
    "\n",
    "                        for j in ids2:\n",
    "                            bundle2 = np.zeros(len(streamlines[subject][bundle_name]))\n",
    "                            bundle2[idx2[j]] = 1\n",
    "\n",
    "                            # scipy's dice function returns the dice *dissimilarity*\n",
    "                            dice_matrix[ii][jj] = 1-dice(bundle1, bundle2)\n",
    "                            jj+=1\n",
    "                    ii+=1\n",
    "                    jj=0\n",
    "\n",
    "            if (big_plots):\n",
    "                plt.figure(figsize = (len(bundle_labels),len(bundle_labels)))\n",
    "                plt.title('dice')\n",
    "                plt.imshow(dice_matrix, cmap='hot', interpolation='nearest')\n",
    "                for (i, j), z in np.ndenumerate(dice_matrix):\n",
    "                    plt.text(j, i, '{:0.2f}'.format(z), ha='center', va='center',\n",
    "                             bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "                plt.colorbar()\n",
    "                plt.xticks(np.arange(len(bundle_labels)), bundle_labels, rotation=90)\n",
    "                plt.yticks(np.arange(len(bundle_labels)), bundle_labels)\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.figure()\n",
    "                plt.title(f'{dataset_name} {subject} {bundle_name}\\n{model_name} dice')\n",
    "                plt.imshow(dice_matrix, cmap='hot', interpolation='nearest')\n",
    "                plt.colorbar()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Bundle Adjacency (BA)](https://www.nature.com/articles/s41598-020-74054-4)\n",
    "\n",
    "> Use bundle adjacency (BA) to calculate the shape similarity between the same type of bundles **across subjects and groups** ... BA uses a minimum direct flip (MDF) distance to get the distance between two streamlines\n",
    "\n",
    "> 𝐵𝐴(𝐵1,𝐵2)=0.5(𝑐𝑜𝑣𝑒𝑟𝑎𝑔𝑒(𝐵1,𝐵2)+𝑐𝑜𝑣𝑒𝑟𝑎𝑔𝑒(𝐵2,𝐵1))\n",
    "\n",
    "> Bundle adjacency is a bounded measure and takes values between 0 to 1, such that 0 means no shape similarity, i.e. no similar adjacent clusters of streamlines were found between the two bundles and 1 means maximum similarity, i.e. all clusters of both bundles had at least one neighbor."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from dipy.segment.bundles import *\n",
    "\n",
    "rng = np.random.RandomState()\n",
    "\n",
    "# assumes 3 clusters per model\n",
    "ba_matrix = np.zeros((len(labels)*3, len(labels)*3))\n",
    "\n",
    "ii=0\n",
    "jj=0\n",
    "for ids1, idx1, label1 in zip(cluster_ids, clusters, labels):\n",
    "    for i in ids1:\n",
    "        tg1 = StatefulTractogram.from_sft(streamlines[idx1[i]], tractogram)\n",
    "        tg1.to_vox()\n",
    "        bundle1 = tg1.streamlines\n",
    "        for ids2, idx2, label2 in zip(cluster_ids, clusters, labels):\n",
    "            for j in ids2:\n",
    "                tg2 = StatefulTractogram.from_sft(streamlines[idx2[j]], tractogram)\n",
    "                tg2.to_vox()\n",
    "                bundle2 = tg2.streamlines\n",
    "#                 ba_matrix[ii][jj] = bundle_shape_similarity(bundle1, bundle2, rng, threshold=1)\n",
    "#                 ba_matrix[ii][jj] = ba_analysis(bundle1, bundle2, threshold=1)\n",
    "#                 ba_matrix[ii][jj] = bundle_adjacency(bundle1, bundle2, threshold=6)\n",
    "                ba_matrix[ii][jj] = bundle_adjacency(bundle1, bundle2, threshold=1)\n",
    "                jj+=1\n",
    "        ii+=1\n",
    "        jj=0\n",
    "\n",
    "if (big_plots):\n",
    "    plt.figure(figsize = (len(bundle_labels),len(bundle_labels)))\n",
    "    plt.title('bundle shape similarity')\n",
    "    # plt.title('bundle analysis')\n",
    "    # plt.title('bundle adjacency')\n",
    "    plt.imshow(ba_matrix, cmap='hot', interpolation='nearest')\n",
    "    for (i, j), z in np.ndenumerate(ba_matrix):\n",
    "        plt.text(j, i, '{:0.2f}'.format(z), ha='center', va='center',\n",
    "                 bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(bundle_labels)), bundle_labels, rotation=90)\n",
    "    plt.yticks(np.arange(len(bundle_labels)), bundle_labels)\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.figure()\n",
    "    plt.title('bundle shape similarity')\n",
    "    # plt.title('bundle analysis')\n",
    "    # plt.title('bundle adjacency')\n",
    "    plt.imshow(ba_matrix, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from  dipy.segment.bundles import *\n",
    "tg1 = StatefulTractogram.from_sft(streamlines[clusters[9][0]], tractogram)\n",
    "tg1.to_vox()\n",
    "bundle1 = tg1.streamlines\n",
    "\n",
    "tg2 = StatefulTractogram.from_sft(streamlines[clusters[9][1]], tractogram)\n",
    "tg2.to_vox()\n",
    "bundle2 = tg2.streamlines\n",
    "\n",
    "\n",
    "clust_thr=[5, 3, 1.5]\n",
    "threshold=1\n",
    "\n",
    "print('bundle_shape_similarity ', bundle_shape_similarity(bundle1, bundle2, rng, clust_thr, threshold))\n",
    "\n",
    "bundle1_centroids = cluster_bundle(bundle1, clust_thr, rng)\n",
    "bundle2_centroids = cluster_bundle(bundle2, clust_thr, rng)\n",
    "bundle1_centroids = Streamlines(bundle1_centroids)\n",
    "bundle2_centroids = Streamlines(bundle2_centroids)\n",
    "\n",
    "print('centriod ba_analysis ', ba_analysis(bundle1_centroids, bundle2_centroids, threshold))\n",
    "\n",
    "nb_pts = 20\n",
    "bundle1_centroids = set_number_of_points(bundle1_centroids, nb_pts)\n",
    "bundle2_centroids = set_number_of_points(bundle2_centroids, nb_pts)\n",
    "\n",
    "print('centriod bundle_adjacency ', bundle_adjacency(bundle1_centroids, bundle2_centroids, threshold))\n",
    "\n",
    "# threshold =1\n",
    "# d01 = bundles_distances_mdf(bundle1, bundle2)\n",
    "# pair12 = []\n",
    "# for i in range(len(bundle1)):\n",
    "#     if np.min(d01[i, :]) < threshold:\n",
    "#         j = np.argmin(d01[i, :])\n",
    "#         pair12.append((i, j))\n",
    "# pair12 = np.array(pair12)\n",
    "# # print(pair12)\n",
    "# pair21 = []\n",
    "\n",
    "# # solo2 = []\n",
    "# for i in range(len(bundle2)):\n",
    "#     if np.min(d01[:, i]) < threshold:\n",
    "#         j = np.argmin(d01[:, i])\n",
    "#         pair21.append((i, j))\n",
    "\n",
    "# pair21 = np.array(pair21)\n",
    "# # print(pair21)\n",
    "# A = len(pair12) / np.float(len(bundle1))\n",
    "# # print(A)\n",
    "# B = len(pair21) / np.float(len(bundle2))\n",
    "# # print(B)\n",
    "# res = 0.5 * (A + B)\n",
    "# print(res)\n",
    "\n",
    "\n",
    "# print(ba_analysis(bundle1, bundle2, threshold=1))\n",
    "# print(bundle_adjacency(bundle1, bundle2, threshold=1))\n",
    "\n",
    "# print(ba_analysis(bundle1_centroids, bundle2_centroids, threshold=1))\n",
    "# print(bundle_adjacency(bundle1_centroids, bundle2_centroids, threshold=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize clustered streamlines\n",
    "\n",
    "- Are there any anatomically distinct subbundles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize subbundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**TODO: `streamtube` plots are not anatomically oriented**</span>\n",
    "\n",
    "<span style=\"color:blue\">**TODO: coordinate `colormap` to make subbundle identification consistent**</span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k = 2 # hier fa\n",
    "\n",
    "colormap_full = np.ones((len(streamlines), 3))\n",
    "colormap = actor.create_colormap(cluster_ids[k])\n",
    "\n",
    "for cluster, color in zip(clusters[k], colormap):\n",
    "    colormap_full[cluster] = color\n",
    "    \n",
    "fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "\n",
    "scene = window.Scene()\n",
    "scene.SetBackground(1, 1, 1)\n",
    "scene.add(actor.streamtube(streamlines, colormap_full))\n",
    "if interact:\n",
    "    window.show(scene, size=(300, 300))\n",
    "window.record(scene, out_path=fname, size=(300, 300))\n",
    "Image(filename=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize subbundles separately"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k = 2 # hier fa\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in cluster_ids[k]:\n",
    "    scene = window.Scene()\n",
    "    scene.SetBackground(1, 1, 1)\n",
    "    scene.add(actor.streamtube(streamlines[clusters[k][i]]))\n",
    "    fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "    if interact:\n",
    "        window.show(scene, size=(300, 300))\n",
    "    window.record(scene, out_path=fname, size=(300, 300))\n",
    "    images.append(Image(filename=fname))\n",
    "    \n",
    "display(*images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALTERNATIVELY: `fury_backend.visualize_bundles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"bright6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize all bundles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "myafq._viz_bundles(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    loc = get_iloc(myafq, subject)\n",
    "    \n",
    "    volume, color_by_volume = myafq._viz_prepare_vols(\n",
    "        myafq.data_frame.loc[loc],\n",
    "        volume=None,\n",
    "        xform_volume=False,\n",
    "        color_by_volume=None,\n",
    "        xform_color_by_volume=False\n",
    "    )\n",
    "    \n",
    "    volumes[subject] = volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize targeted bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    if subject != '103818':\n",
    "        continue\n",
    "    volume = volumes[subject]\n",
    "    for bundle_name in bundle_names:\n",
    "        tg = StatefulTractogram.from_sft(streamlines[subject][bundle_name], tractograms[subject][bundle_name])\n",
    "        tg.to_vox()\n",
    "\n",
    "        if False:\n",
    "            scene = visualize_bundles(\n",
    "                tractogram,\n",
    "                colors=[(0,0,0)],\n",
    "                figure=volume_figure\n",
    "            ) #inline, interact\n",
    "        else:\n",
    "            scene = window.Scene()\n",
    "\n",
    "            figure = visualize_volume(\n",
    "                volume,\n",
    "                interact=False,\n",
    "                inline=False,\n",
    "                figure=scene\n",
    "            )\n",
    "\n",
    "            figure.SetBackground(1,1,1)\n",
    "\n",
    "            # orange\n",
    "            orange = (255/255,165/255,0)\n",
    "            gold = (255/255,215/255,0)\n",
    "\n",
    "            streamline_actor = actor.streamtube(tg.streamlines, colors=gold, linewidth=0.6)\n",
    "            figure.add(streamline_actor)\n",
    "        \n",
    "        fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "        window.snapshot(scene, fname=fname, size=(600, 400))\n",
    "        plt.imshow(plt.imread(fname))\n",
    "        plt.title(f'{dataset_name} {subject} {bundle_name}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        scene.azimuth(90)\n",
    "        scene.roll(90)\n",
    "        window.snapshot(scene, fname=fname, size=(600, 400))\n",
    "        plt.imshow(plt.imread(fname))\n",
    "        plt.title(f'{dataset_name} {subject} {bundle_name}')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize subbundles separately"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k = 10\n",
    "\n",
    "for i in cluster_ids[k]:\n",
    "    volume_figure = visualize_volume(\n",
    "        volume,\n",
    "        interact=False,\n",
    "        inline=False\n",
    "    )\n",
    "\n",
    "\n",
    "    tg = StatefulTractogram.from_sft(streamlines[clusters[k][i]], tractogram)\n",
    "    tg.to_vox()\n",
    "    scene = visualize_bundles(tg, figure=volume_figure) #inline, interact\n",
    "\n",
    "    if interact:\n",
    "        window.show(scene, size=(300, 300))\n",
    "\n",
    "    fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "    window.snapshot(scene, fname=fname, size=(300, 300))\n",
    "    display(Image(fname))\n",
    "    scene.azimuth(90)\n",
    "    scene.roll(90)\n",
    "    window.snapshot(scene, fname=fname, size=(300, 300))\n",
    "    display(Image(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize subbundles\n",
    "\n",
    "<span style=\"color:blue\">**TODO: Color bundles bug in fury `visualize_bundles`.**</span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k = 10\n",
    "\n",
    "figure = visualize_volume(\n",
    "    volume,\n",
    "    interact=False,\n",
    "    inline=False\n",
    ")\n",
    "\n",
    "for i in cluster_ids[k]:    \n",
    "    tg = StatefulTractogram.from_sft(streamlines[clusters[k][i]], tractogram)\n",
    "    tg.to_vox()\n",
    "    \n",
    "    figure = visualize_bundles(tg, colors=[colors[i]], figure=figure)\n",
    "    if interact:\n",
    "        window.show(figure, size=(300, 300))\n",
    "\n",
    "fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "window.snapshot(figure, fname=fname, size=(300, 300))\n",
    "display(Image(fname))\n",
    "\n",
    "figure.azimuth(270)\n",
    "figure.roll(270)\n",
    "fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "window.snapshot(figure, fname=fname, size=(300, 300))\n",
    "display(Image(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**TODO: `azimuth` hides the volume.**</span>\n",
    "\n",
    "Similar comment from old vtk thread http://vtk.1045678.n5.nabble.com/Flipping-the-image-with-vtkCamera-Yaw-makes-image-disappear-td1243738.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.viz import ui\n",
    "\n",
    "# fa\n",
    "for subject in subjects:\n",
    "    if subject != '103818':\n",
    "        continue\n",
    "    volume = volumes[subject]\n",
    "    for bundle_name in bundle_names:\n",
    "        for ids, idx, label in zip(cluster_ids[subject][bundle_name], clusters[subject][bundle_name], labels[subject][bundle_name]):\n",
    "            if not('sc' in label and 'pairwise' in label and 'mdf' in label):\n",
    "                continue\n",
    "            \n",
    "#             print(f'{subject} {bundle_name} {label} axial')\n",
    "\n",
    "#             title = ui.TextBlock2D(text=f'{subject} {bundle_name} {label}',\n",
    "#                                    color=(0,0,0))\n",
    "                        \n",
    "            scene = window.Scene()\n",
    "      \n",
    "            figure = visualize_volume(\n",
    "                volume,\n",
    "                interact=False,\n",
    "                inline=False,\n",
    "                figure=scene\n",
    "            )\n",
    "\n",
    "            figure.SetBackground(1,1,1)\n",
    "\n",
    "            for i in ids:    \n",
    "                tg = StatefulTractogram.from_sft(streamlines[subject][bundle_name][idx[i]], tractograms[subject][bundle_name])\n",
    "                tg.to_vox()\n",
    "\n",
    "#                 streamline_actor = actor.streamtube(tg.streamlines, colors[i]) #, linewidth=.6)\n",
    "#                 streamline_actor.GetProperty().SetBackfaceCulling(False)\n",
    "\n",
    "                # https://github.com/fury-gl/fury/issues/114\n",
    "#                 streamline_actor = actor.streamtube(tg.streamlines, colors[i], lod=False)\n",
    "\n",
    "                streamline_actor = actor.streamtube(tg.streamlines, colors[i], linewidth=0.6)\n",
    "\n",
    "                # TODO debugging streamline width        \n",
    "        #         streamline_actor.GetProperty().SetRenderLinesAsTubes(True)\n",
    "        #         streamline_actor.GetProperty().SetLineWidth(6)\n",
    "        #         print(streamline_actor.GetProperty())\n",
    "\n",
    "                figure.add(streamline_actor)\n",
    "\n",
    "                if interact:\n",
    "                    window.show(figure, size=(600, 400))\n",
    "\n",
    "        #     image_actor_z = actor.slicer(volume, opacity=0.6)\n",
    "        #     figure.add(image_actor_z)\n",
    "        \n",
    "#             scene.add(title)\n",
    "\n",
    "#             showm = window.ShowManager(scene)\n",
    "#             showm.scene.add(title)\n",
    "\n",
    "            # Why is scene vertically reflected compare window.show(scene) versus window.snapshot(scene)\n",
    "            # See similar issue http://vtk.1045678.n5.nabble.com/Problem-with-upside-down-image-itk-vtk-td5716361.html\n",
    "        \n",
    "#             scene.set_camera(view_up=(1,0,0))\n",
    "#             display(scene.camera_info())\n",
    "#             display(window.analyze_scene(scene).actors)\n",
    "            \n",
    "                    \n",
    "            fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "            window.snapshot(scene, fname=fname, size=(600, 400))\n",
    "#             display(Image(fname))\n",
    "            \n",
    "            # work around for title see\n",
    "            # http://vtk.1045678.n5.nabble.com/vtkCaptionActor2D-text-orientation-td1232191.html\n",
    "            plt.imshow(plt.imread(fname))\n",
    "            plt.title(f'{dataset_name} {subject} {bundle_name}\\n{label}')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "#             print(f'{subject} {bundle_name} {label} sagittal')\n",
    "            figure.azimuth(90)\n",
    "            figure.roll(90)\n",
    "\n",
    "        #     image_actor_x = image_actor_z.copy()\n",
    "        #     image_actor_x.display(image_actor_x.shape[0]//2, None, None)\n",
    "\n",
    "        #     image_actor_x = image_actor_z.copy()\n",
    "        #     x_midpoint = int(np.round(image_actor_x.shape[0] / 2))\n",
    "        #     image_actor_x.display_extent(x_midpoint,\n",
    "        #                                  x_midpoint, 0,\n",
    "        #                                  image_actor_x.shape[1] - 1,\n",
    "        #                                  0,\n",
    "        #                                  image_actor_x.shape[2] - 1)\n",
    "\n",
    "        #     figure.add(image_actor_x)\n",
    "            \n",
    "#             window.show(scene, reset_camera=False)\n",
    "            fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "            window.snapshot(figure, fname=fname, size=(600, 400))\n",
    "#             display(Image(fname))\n",
    "            \n",
    "#             assert False\n",
    "            plt.imshow(plt.imread(fname))\n",
    "            plt.title(f'{dataset_name} {subject} {bundle_name}\\n{label}')\n",
    "            plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**TODO: Currently Debugging.**</span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "figure = window.Scene()\n",
    "\n",
    "# https://vtk.org/doc/nightly/html/classvtkRenderer.html\n",
    "# print(figure.GetTwoSidedLighting())\n",
    "# print(figure.GetLightFollowCamera())\n",
    "\n",
    "import AFQ.viz.utils as vut\n",
    "volume = vut.load_volume(volume)\n",
    "\n",
    "figure.SetBackground(1,1,1)\n",
    "\n",
    "tg = StatefulTractogram.from_sft(streamlines[clusters[0][0]], tractogram)\n",
    "tg.to_vox()\n",
    "\n",
    "streamline_actor = actor.streamtube(tg.streamlines, colors[0])\n",
    "figure.add(streamline_actor)\n",
    "\n",
    "# print(streamline_actor.GetBounds())\n",
    "# print(streamline_actor.GetCenter())\n",
    "# print(streamline_actor.GetDebug())\n",
    "# print(streamline_actor.GetForceOpaque())\n",
    "# print(streamline_actor.GetForceTranslucent())\n",
    "# print(streamline_actor.GetLength())\n",
    "# print(streamline_actor.GetNumberOfPaths())\n",
    "# print(streamline_actor.GetOrientation())\n",
    "# print(streamline_actor.GetOrigin())\n",
    "# print(streamline_actor.GetPosition())\n",
    "\n",
    "image_actor_z = actor.slicer(volume, opacity=.6)\n",
    "figure.add(image_actor_z)\n",
    "\n",
    "for i in range(0, volume.shape[0], 10):\n",
    "    image_actor = image_actor_z.copy()\n",
    "    image_actor.display(i, None, None)\n",
    "    figure.add(image_actor)\n",
    "\n",
    "# image_actor.display_extent(image_actor.shape[0] // 2,\n",
    "#                            image_actor.shape[0] // 2,\n",
    "#                            0,\n",
    "#                            image_actor.shape[1]-1,\n",
    "#                            0,\n",
    "#                            image_actor.shape[2]-1)\n",
    "# figure.add(image_actor)\n",
    "\n",
    "if interact:\n",
    "    window.show(figure, title=f'{bundle_name}', size=(300, 300))  \n",
    "\n",
    "fname = tempfile.NamedTemporaryFile().name + '.png'\n",
    "window.snapshot(figure, fname=fname, size=(300, 300))\n",
    "display(Image(fname))\n",
    "\n",
    "# VTK properties\n",
    "# https://vtk.org/doc/nightly/html/classvtkImageSlice.html\n",
    "# \n",
    "# print(image_actor.GetInterpolate())\n",
    "# print(image_actor.GetOpacity())\n",
    "# print(image_actor.GetDisplayExtent())\n",
    "# print(image_actor.GetBounds())\n",
    "# print(image_actor.GetDisplayBounds())\n",
    "# print(image_actor.GetSliceNumber())\n",
    "# print(image_actor.GetZSlice())\n",
    "# print(image_actor.GetForceOpaque())\n",
    "# \n",
    "# print(image_actor.GetForceTranslucent())\n",
    "# print(image_actor.GetOrigin())\n",
    "# print(image_actor.GetScale())\n",
    "# print(image_actor.GetCenter())\n",
    "# print(image_actor.GetOrientation())\n",
    "\n",
    "\n",
    "# figure_actors = figure.GetActors()\n",
    "# \n",
    "# print(figure_actors.GetNumberOfItems())\n",
    "# \n",
    "# for figure_actor in figure_actors:\n",
    "#     print(figure_actor.IsRenderingTranslucentPolygonalGeometry())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**TODO: add profile and anatomical for individual clusters**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot tract profiles for clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_scalar_filename(myafq, 'dti_fa', loc))\n",
    "# !ls -la /Users/bloomdt/AFQ_data/HCP_1200/derivatives/afq/sub-103818/ses-01/sub-103818_dwi_model-dti_fa.nii.gz\n",
    "\n",
    "for subject in subjects:\n",
    "\n",
    "    if subject != '103818':\n",
    "        continue\n",
    "        \n",
    "    loc = get_iloc(myafq, subject)\n",
    "    fa_scalar_data = nib.load(get_scalar_filename(myafq, 'dti_fa', loc)).get_fdata()\n",
    "#     print(np.count_nonzero(np.array(fa_scalar_data)))\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(f\"{dataset_name} {subject} {bundle_name}\\n fa tract profiles\")\n",
    "        plt.plot(\n",
    "            afq_profile(\n",
    "                fa_scalar_data,\n",
    "                streamlines[subject][bundle_name],\n",
    "                affines[subject][bundle_name],\n",
    "                weights=gaussian_weights(streamlines[subject][bundle_name])\n",
    "            ), \n",
    "            color='k'\n",
    "        )\n",
    "        plt.xlabel('node index')\n",
    "        plt.ylabel('dta_fa values')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        for ids, idx, label in zip(cluster_ids[subject][bundle_name], clusters[subject][bundle_name], labels[subject][bundle_name]):\n",
    "            if not('sc' in label and 'pairwise' in label and 'mdf' in label):\n",
    "                continue\n",
    "                \n",
    "            profiles = []\n",
    "\n",
    "            plt.figure()\n",
    "            for i in ids:\n",
    "                profile = afq_profile(\n",
    "                    fa_scalar_data,\n",
    "                    streamlines[subject][bundle_name][idx[i]],\n",
    "                    affines[subject][bundle_name],\n",
    "                    weights=gaussian_weights(streamlines[subject][bundle_name][idx[i]])\n",
    "                )\n",
    "                plt.plot(profile, color=colors[i], label=f\"cluster {i}\")\n",
    "                profiles.append(profile)\n",
    "                \n",
    "            # Calculate Pearson correlations between profiles\n",
    "            corr = pd.DataFrame(zip(*profiles), columns=ids).corr()\n",
    "            plt.title(f\"{dataset_name} {subject} {bundle_name}\\n{label} tract profiles\\n {corr}\")\n",
    "            plt.xlabel('node index')\n",
    "            plt.ylabel('dta_fa values')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "md_scalar_data = nib.load(get_scalar_filename(myafq, 'dti_md', loc)).get_fdata()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"{bundle_name} md tract profiles\")\n",
    "plt.plot(afq_profile(\n",
    "    md_scalar_data,\n",
    "    streamlines,\n",
    "    affine,\n",
    "    weights=gaussian_weights(streamlines)\n",
    "))\n",
    "plt.show()\n",
    "\n",
    "#for name, ids, idx in zip(labels[6:9], cluster_ids[6:9], clusters[6:9]):\n",
    "    plt.figure()\n",
    "    plt.title(f\"{name} tract profiles\")\n",
    "    for i in ids:\n",
    "        plt.plot(afq_profile(\n",
    "            md_scalar_data,\n",
    "            streamlines[idx[i]],\n",
    "            affine,\n",
    "            weights=gaussian_weights(streamlines[idx[i]])\n",
    "        ), color=colors[i], label=f\"cluster {i}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save individual subbundle tractography files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in fa_cluster_ids:\n",
    "    tg = StatefulTractogram.from_sft(streamlines[fa_clusters[i-1]], tractogram)\n",
    "    tempdir = tempfile.gettempdir()\n",
    "    fname = op.join(tempdir, f'cluster{i-1}.trk')\n",
    "    save_tractogram(tg, fname, bbox_valid_check=False)\n",
    "    print(fname)\n",
    "\n",
    "for i in md_cluster_ids:\n",
    "    tg = StatefulTractogram.from_sft(streamlines[md_clusters[i-1]], tractogram)\n",
    "    tempdir = tempfile.gettempdir()\n",
    "    fname = op.join(tempdir, f'cluster{i-1}.trk')\n",
    "    save_tractogram(tg, fname, bbox_valid_check=False)\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
