{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subbundles Part 4: Adjacencies\n",
    "\n",
    "**Subbundle** - a subgroup of streamlines with a set of common properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import time\n",
    "import os.path as op\n",
    "\n",
    "from AFQ import api\n",
    "import AFQ.data as afd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from dipy.io.streamline import load_tractogram\n",
    "import dipy.tracking.streamline as dts\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlines (from Part 2) and Streamline Profiles (from Part 3)\n",
    "\n",
    "Streamlines are necessary to calculate mfd adjacency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance/Adjacency Matrix of Streamline Correlations\n",
    "\n",
    "An $N \\times N$ matrix of coorelations of streamline tract profiles, where $N$ is the number of streamline profiles\n",
    "  \n",
    "  - **single matrix and single metric**\n",
    "  \n",
    "  - **single matrix and multiple metrics (weighted linear combination)**\n",
    "    \n",
    "    - manually stacked \n",
    "      \n",
    "    - learn hyperparameters\n",
    "      \n",
    "  - *multiple matrices (tensor) and multiple metrics* (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamline Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">NOTE: There are multiple correlation metrics, using Pearson's r</span>\n",
    "\n",
    "- <span style=\"color:red\">**Question: are streamline profiles considered: measurement, ordinal, or categorical?**</span>\n",
    "\n",
    "  - For now stick with Pearson's r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_test_retest = False\n",
    "# compare_test_retest = True\n",
    "\n",
    "test_retest_sessions = ['test', 'retest']\n",
    "test_retest_names = ['HCP', 'HCP_retest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'HCP'\n",
    "dataset_name = 'HCP_retest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = get_subjects(dataset_name)\n",
    "subjects = get_subjects_small(dataset_name)\n",
    "# subjects = get_subjects_medium(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_test_retest:\n",
    "    print('HCP')\n",
    "    myafq_test = get_afq('HCP')\n",
    "    display(myafq_test.data_frame)\n",
    "    \n",
    "    print('HCP_retest')\n",
    "    myafq_retest = get_afq('HCP_retest')\n",
    "    display(myafq_retest.data_frame)\n",
    "else:\n",
    "    print(dataset_name)\n",
    "    myafq = get_afq(dataset_name)\n",
    "    display(myafq.data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if compare_test_retest:\n",
    "#     bundle_names = [*myafq_retest.bundle_dict]\n",
    "# else:\n",
    "#     bundle_names = [*myafq.bundle_dict]\n",
    "\n",
    "# bundle_names = ['SLF_L', 'SLF_R']\n",
    "# bundle_names = ['ARC_L', 'ARC_R', 'CST_L', 'CST_R', 'FP'] \n",
    "bundle_names = ['SLF_L', 'SLF_R', 'ARC_L', 'ARC_R', 'CST_L', 'CST_R', 'FP']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "feature_files = {}\n",
    "target_dirs = {}\n",
    "fa_values = {}\n",
    "mean_warped_fa_values = {}\n",
    "pairwise_warped_fa_values = {}\n",
    "md_values = {}\n",
    "mean_warped_md_values = {}\n",
    "pairwise_warped_md_values = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    feature_files[subject] = {}\n",
    "    target_dirs[subject] = {}\n",
    "    fa_values[subject] = {}\n",
    "    mean_warped_fa_values[subject] = {}\n",
    "    pairwise_warped_fa_values[subject] = {}\n",
    "    md_values[subject] = {}\n",
    "    mean_warped_md_values[subject] = {}\n",
    "    pairwise_warped_md_values[subject] = {}\n",
    "        \n",
    "    if compare_test_retest:\n",
    "        loc_test  = get_iloc(myafq_test, subject)\n",
    "        loc_retest = get_iloc(myafq_retest, subject)\n",
    "    else:\n",
    "        loc = get_iloc(myafq, subject)\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        feature_files[subject][bundle_name] = {}\n",
    "        target_dirs[subject][bundle_name] = {}\n",
    "        fa_values[subject][bundle_name] = {}\n",
    "        mean_warped_fa_values[subject][bundle_name] = {}\n",
    "        pairwise_warped_fa_values[subject][bundle_name] = {}\n",
    "        md_values[subject][bundle_name] = {}\n",
    "        mean_warped_md_values[subject][bundle_name] = {}\n",
    "        pairwise_warped_md_values[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions, [myafq_test, myafq_retest], [loc_test, loc_retest])\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name], [myafq], [loc])\n",
    "\n",
    "        for name, ses, myafq, loc in iterables:\n",
    "            feature_files[subject][bundle_name][ses] = []\n",
    "            \n",
    "            target_dir = get_dir_name(myafq, dataset_name, bundle_name, loc)\n",
    "            target_dirs[subject][bundle_name][ses] = target_dir\n",
    "#             print(name, subject, bundle_name, ses, target_dir)\n",
    "\n",
    "            # TODO consider using myafq.scalars\n",
    "            # TODO consider optionally specifying scalars of interest\n",
    "\n",
    "            fa_f_name = op.join(target_dir, 'streamline_profile_fa.npy');\n",
    "            if op.isfile(fa_f_name):\n",
    "                feature_files[subject][bundle_name][ses].append(fa_f_name)\n",
    "                fa_values[subject][bundle_name][ses] = np.load(fa_f_name)\n",
    "    #             print(name, subject, bundle_name, ses, fa_f_name)\n",
    "            \n",
    "            md_f_name = op.join(target_dir, 'streamline_profile_md.npy')\n",
    "            if op.isfile(md_f_name):\n",
    "                feature_files[subject][bundle_name][ses].append(md_f_name)\n",
    "                md_values[subject][bundle_name][ses] = np.load(md_f_name)\n",
    "    #             print(name, subject, bundle_name, ses, md_f_name)\n",
    "\n",
    "            # reference warped: mean\n",
    "            fa_f_name = op.join(target_dir, 'streamline_profile_ref_warped_fa.npy')\n",
    "            if op.isfile(fa_f_name):\n",
    "                feature_files[subject][bundle_name][ses].append(fa_f_name)\n",
    "                mean_warped_fa_values[subject][bundle_name][ses] = np.load(fa_f_name)\n",
    "    #             print(name, subject, bundle_name, ses, fa_f_name)\n",
    "\n",
    "            md_f_name = op.join(target_dir, 'streamline_profile_ref_warped_md.npy')\n",
    "            if op.isfile(md_f_name):\n",
    "                feature_files[subject][bundle_name][ses].append(md_f_name)\n",
    "                mean_warped_md_values[subject][bundle_name][ses] = np.load(md_f_name)\n",
    "    #             print(name, subject, bundle_name, ses, md_f_name)\n",
    "\n",
    "            # pairwise warped\n",
    "            fa_f_name = op.join(target_dir, 'streamline_profile_pairwise_warped_fa.npy')\n",
    "            if op.isfile(fa_f_name):\n",
    "                feature_files[subject][bundle_name][ses].append(fa_f_name)\n",
    "                pairwise_warped_fa_values[subject][bundle_name][ses] = np.load(fa_f_name)\n",
    "    #             print(name, subject, bundle_name, ses, fa_f_name)\n",
    "\n",
    "            md_f_name = op.join(target_dir, 'streamline_profile_pairwise_warped_md.npy')\n",
    "            if op.isfile(md_f_name):\n",
    "                feature_files[subject][bundle_name][ses].append(md_f_name)\n",
    "                pairwise_warped_md_values[subject][bundle_name][ses] = np.load(md_f_name)\n",
    "    #             print(name, subject, bundle_name, ses, md_f_name)\n",
    "\n",
    "            # validation information\n",
    "            validate = False\n",
    "            \n",
    "            if validate:\n",
    "                print(name, subject, bundle_name, ses)\n",
    "                streamline_tract_profile_test(fa_values[subject][bundle_name][ses])\n",
    "                streamline_tract_profile_test(mean_warped_fa_values[subject][bundle_name][ses])\n",
    "                streamline_tract_profile_test(md_values[subject][bundle_name][ses])\n",
    "                streamline_tract_profile_test(mean_warped_md_values[subject][bundle_name][ses])\n",
    "\n",
    "features_df = pd.DataFrame.from_dict(\n",
    "    {(i,j,k): feature_files[i][j][k] for i in feature_files.keys() for j in feature_files[i].keys() for k in feature_files[i][j].keys()}, \n",
    "    orient='index', \n",
    "    columns=['fa', 'md', 'mean_fa', 'mean_md', 'pairwise_fa', 'pairwise_md']\n",
    ")\n",
    "\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(features_df)\n",
    "    \n",
    "os.makedirs(op.join('subbundles', dataset_name), exist_ok=True)\n",
    "f_name = op.join('subbundles', dataset_name, f'feature_files.csv')\n",
    "print(f_name)\n",
    "features_df.to_csv(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    target_dirs[subject] = {}\n",
    "    \n",
    "    if compare_test_retest:\n",
    "        loc_test  = get_iloc(myafq_test, subject)\n",
    "        loc_retest = get_iloc(myafq_retest, subject)\n",
    "    else:\n",
    "        loc = get_iloc(myafq, subject)\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        target_dirs[subject][bundle_name] = {}\n",
    "        \n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions, [myafq_test, myafq_retest], [loc_test, loc_retest])\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name], [myafq], [loc])\n",
    "\n",
    "        for name, ses, myafq, loc in iterables:\n",
    "            target_dir = get_dir_name(myafq, dataset_name, bundle_name, loc)\n",
    "            target_dirs[subject][bundle_name][ses] = target_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">NOTE: There are multiple python implementations to compute correlation</span>\n",
    "\n",
    "- Haven't [compared or contrasted benefits](https://realpython.com/numpy-scipy-pandas-correlation-python/) of `NumPy`, `SciPy`, or `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Candidiate [Correlation Coefficients](https://en.wikipedia.org/wiki/Correlation_coefficient#Types):\n",
    "\n",
    "- Pearson's r\n",
    "\n",
    "- [Rank correlation](https://en.wikipedia.org/wiki/Rank_correlation) coefficients\n",
    "\n",
    "  - Spearman's $\\rho$\n",
    "\n",
    "  - Kendall's $\\tau$\n",
    "  \n",
    "  - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA (Fractional Anisotropy)\n",
    "\n",
    "One of the scalars calculated from DWI.\n",
    "\n",
    "More focus has been placed on FA since Schurr's paper indicates FA can be used to isolate SLF subbundles."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fa_dfs = {}\n",
    "fa_corrs = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    fa_dfs[subject] = {}\n",
    "    fa_corrs[subject] = {}\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        fa_dfs[subject][bundle_name] = {}\n",
    "        fa_corrs[subject][bundle_name] = {}\n",
    "        \n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in fa_values[subject][bundle_name]:\n",
    "                print(dataset_name, subject, bundle_name, 'fa', 'no values')\n",
    "                continue\n",
    "            \n",
    "            fa_df = pd.DataFrame(fa_values[subject][bundle_name][ses].T)\n",
    "            fa_dfs[subject][bundle_name][ses] = fa_df\n",
    "            fa_corr = fa_df.corr()\n",
    "            fa_corrs[subject][bundle_name][ses] = fa_corr\n",
    "\n",
    "            if not compare_test_retest:\n",
    "                target_dir = target_dirs[subject][bundle_name][ses]\n",
    "                f_name = op.join(target_dir,'adjacency_fa.npy')\n",
    "                np.save(f_name, fa_corr.to_numpy())\n",
    "                print(dataset_name, subject, bundle_name, 'fa', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_corrs = {}\n",
    "for subject in subjects:\n",
    "    fa_corrs[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        fa_corrs[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_fa.npy')\n",
    "            if op.isfile(f_name):\n",
    "                fa_corrs[subject][bundle_name][ses] = np.load(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute Difference in $\\mu$ FA (mean Fractional Anisotropy)\n",
    "\n",
    "Origially requested by Jason, but supplanted in favor of coefficient of determiniation since it also takes into account variance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if not compare_test_retest:\n",
    "    for subject in subjects:\n",
    "        for bundle_name in bundle_names:\n",
    "            fa_df = fa_dfs[subject][bundle_name]\n",
    "\n",
    "            fa_mu = pd.DataFrame([[np.absolute(a-b) for a in fa_df.mean()] for b in fa_df.mean()])\n",
    "\n",
    "            f_name = op.join(target_dir,'adjacency_fa_mu.npy')\n",
    "            np.save(f_name, fa_mu.to_numpy())\n",
    "            print(dataset_name, subject, bundle_name, 'fa_mu', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient of Determination: $R^2$\n",
    "\n",
    "In Schurr 2019 paper, main differentiating factors between SLFII and the other SLF sections are offsets in the mean FA between streamlines. \n",
    "\n",
    "Consider use a distance function that takes into account the offset, and not only co-variation, like:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### examplar coefficent of determination"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def coeff_of_determination(data, model, axis=-1):\n",
    "    \"\"\"\n",
    "     http://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "              _                                            _\n",
    "             |    sum of the squared residuals              |\n",
    "    R^2 =    |1 - ---------------------------------------   | * 100\n",
    "             |_    sum of the squared mean-subtracted data _|\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.empty((data.shape[0], model.shape[0]))\n",
    "    demeaned_data = data - np.mean(data, axis=axis)[...,np.newaxis]\n",
    "    ss_tot = np.sum(demeaned_data **2, axis=axis)\n",
    "    # Don't divide by 0:\n",
    "    if np.all(ss_tot==0.0):\n",
    "        X[:, :] = np.nan\n",
    "        return X\n",
    "\n",
    "    for ii in range(X.shape[0]):\n",
    "        for jj in range(X.shape[1]):\n",
    "            # There's no point in doing any of this: \n",
    "            if np.all(data[ii]==0.0) and np.all(model[ii]==0.0):\n",
    "                X[ii, jj] = np.nan\n",
    "            else:\n",
    "                residuals = data[ii] - model[jj]\n",
    "                ss_err = np.sum(residuals ** 2, axis=axis)\n",
    "                X[ii, jj] = 1 - (ss_err/ss_tot[ii])\n",
    "\n",
    "    \n",
    "    return X\n",
    "\n",
    "fa_r2_ = coeff_of_determination(fa_values, fa_values)\n",
    "adjacency_test(fa_r2)\n",
    "adjacency_test(fa_r2_)\n",
    "fa_r2-fa_r2_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FA $R^2$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fa_r2s = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    fa_r2s[subject] = {}\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        fa_r2s[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_fa_r2.npy')\n",
    "            \n",
    "            if compare_test_retest:    \n",
    "                fa_r2s[subject][bundle_name][ses] = np.load(f_name)\n",
    "                print(name, subject, bundle_name, 'fa_r2', 'loading', f_name)\n",
    "            else:\n",
    "                if not ses in fa_values[subject][bundle_name]:\n",
    "                    print(dataset_name, subject, bundle_name, 'fa_r2', 'no values')\n",
    "                    continue\n",
    "                    \n",
    "                values = fa_values[subject][bundle_name][ses]\n",
    "                \n",
    "                tic = time.perf_counter()\n",
    "                fa_r2 = pd.DataFrame([[r2_score(a,b) for a in values] for b in values])\n",
    "                # Note: to make symmetric calculate inverse then average\n",
    "                fa_r2 += fa_r2.T\n",
    "                fa_r2 = fa_r2/2\n",
    "                fa_r2s[subject][bundle_name][ses] = fa_r2\n",
    "                toc = time.perf_counter()\n",
    "                print(dataset_name, subject, bundle_name, f'{toc - tic:0.4f} seconds')\n",
    "\n",
    "                np.save(f_name, fa_r2.to_numpy())\n",
    "                print(dataset_name, subject, bundle_name, 'fa_r2', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_r2s = {}\n",
    "for subject in subjects:\n",
    "    fa_r2s[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        fa_r2s[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_fa_r2.npy')\n",
    "            if op.isfile(f_name):\n",
    "                fa_r2s[subject][bundle_name][ses] = np.load(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   $\\mu$-Reference  Warped FA $R^2$\n",
    "\n",
    "The streamline profiles have been warped based on a reference streamline. Here the reference is a pseudo-streamline with the mean FA value across the bundle at each point."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean_warped_fa_r2s = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    mean_warped_fa_r2s[subject] = {}\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        mean_warped_fa_r2s[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_ref_warped_fa_r2.npy')\n",
    "            \n",
    "            if compare_test_retest:\n",
    "                mean_warped_fa_r2s[subject][bundle_name][ses] = np.load(f_name)\n",
    "                print(name, subject, bundle_name, 'warped_fa_r2', 'loading', f_name)\n",
    "            else:\n",
    "                if not ses in fa_values[subject][bundle_name]:\n",
    "                    print(dataset_name, subject, bundle_name, 'warped_fa_r2', 'no values')\n",
    "                    continue\n",
    "                \n",
    "                values = mean_warped_fa_values[subject][bundle_name][ses]\n",
    "\n",
    "                tic = time.perf_counter()\n",
    "                fa_r2 = pd.DataFrame([[r2_score(a,b) for a in values] for b in values])\n",
    "                # Note: to make symmetric calculate inverse then average\n",
    "                fa_r2 += fa_r2.T\n",
    "                fa_r2 = fa_r2/2\n",
    "                mean_warped_fa_r2s[subject][bundle_name][ses] = fa_r2\n",
    "                toc = time.perf_counter()\n",
    "                print(dataset_name, subject, bundle_name, f'{toc - tic:0.4f} seconds')\n",
    "\n",
    "                np.save(f_name, fa_r2.to_numpy())\n",
    "                print(dataset_name, subject, bundle_name, 'warped_fa_r2', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_warped_fa_r2s = {}\n",
    "for subject in subjects:\n",
    "    mean_warped_fa_r2s[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        mean_warped_fa_r2s[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_ref_warped_fa_r2.npy')\n",
    "            if op.isfile(f_name):\n",
    "                mean_warped_fa_r2s[subject][bundle_name][ses] = np.load(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Pairwise Warped FA $R^2$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pairwise_warped_fa_r2s = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    pairwise_warped_fa_r2s[subject] = {}\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        pairwise_warped_fa_r2s[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_pairwise_warped_fa_r2.npy')\n",
    "            \n",
    "            if compare_test_retest:\n",
    "                pairwise_warped_fa_r2s[subject][bundle_name][ses] = np.load(f_name)\n",
    "                print(name, subject, bundle_name, 'pairwise_warped_fa_r2', 'loading', f_name)\n",
    "            else:\n",
    "                if not ses in fa_values[subject][bundle_name]:\n",
    "                    print(dataset_name, subject, bundle_name, 'pairwise_warped_fa_r2', 'no values')\n",
    "                    continue\n",
    "                \n",
    "                # To calculate a NxN for the R^2, compare each warped streamline profile \n",
    "                # to the unwarped target streamline\n",
    "                unwarped_fa_values = fa_values[subject][bundle_name][ses]\n",
    "                warped_fa_values = pairwise_warped_fa_values[subject][bundle_name][ses]\n",
    "\n",
    "                tic = time.perf_counter()\n",
    "                fa_r2 = pd.DataFrame(\n",
    "                    [\n",
    "                        [\n",
    "                            r2_score(warped_fa_values[i][j], unwarped_fa_values[i]) \n",
    "                             for j in np.ndindex(warped_fa_values.shape[1])\n",
    "                        ]\n",
    "                        for i in np.ndindex(warped_fa_values.shape[0])\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                # Note: to make symmetric calculate inverse then average\n",
    "                fa_r2 += fa_r2.T\n",
    "                fa_r2 = fa_r2/2\n",
    "                toc = time.perf_counter()\n",
    "                print(dataset_name, subject, bundle_name, f'{toc - tic:0.4f} seconds')\n",
    "                print(fa_r2.shape)\n",
    "\n",
    "                pairwise_warped_fa_r2s[subject][bundle_name][ses] = fa_r2\n",
    "\n",
    "                np.save(f_name, fa_r2.to_numpy())\n",
    "                print(dataset_name, subject, bundle_name, 'pairwise_warped_fa_r2', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_warped_fa_r2s = {}\n",
    "for subject in subjects:\n",
    "    pairwise_warped_fa_r2s[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        pairwise_warped_fa_r2s[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_pairwise_warped_fa_r2.npy')\n",
    "            if op.isfile(f_name):\n",
    "                pairwise_warped_fa_r2s[subject][bundle_name][ses] = np.load(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MD (Mean Diffusivity)\n",
    "\n",
    "One of the scalars calculated from DWI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "md_dfs = {}\n",
    "md_corrs = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    md_dfs[subject] = {}\n",
    "    md_corrs[subject] = {}\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        md_dfs[subject][bundle_name] = {}\n",
    "        md_corrs[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in md_values[subject][bundle_name]:\n",
    "                print(dataset_name, subject, bundle_name, 'md', 'no values')\n",
    "                continue\n",
    "                \n",
    "            md_df = pd.DataFrame(md_values[subject][bundle_name][ses].T)\n",
    "            md_dfs[subject][bundle_name][ses] = md_df\n",
    "\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_md.npy')\n",
    "            \n",
    "            if compare_test_retest:\n",
    "                md_corrs[subject][bundle_name][ses] = np.load(f_name)\n",
    "                print(name, subject, bundle_name, 'md', 'loading', f_name)\n",
    "            else:\n",
    "                md_corr = md_df.corr()\n",
    "                md_corrs[subject][bundle_name][ses] = md_corr\n",
    "            \n",
    "                np.save(f_name, md_corr.to_numpy())\n",
    "                print(dataset_name, subject, bundle_name, 'md', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_corrs = {}\n",
    "for subject in subjects:\n",
    "    md_corrs[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        md_corrs[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_md.npy')\n",
    "            if op.isfile(f_name):\n",
    "                md_corrs[subject][bundle_name][ses] = np.load(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Metrics\n",
    "\n",
    "Given: \n",
    "\n",
    "- NxN streamlines \n",
    "\n",
    "Assuming:\n",
    "\n",
    "- same subject\n",
    "\n",
    "- same streamlines\n",
    "\n",
    "Anything varies streamlines would violate assumptions:\n",
    "\n",
    "- comparing subjects\n",
    "\n",
    "- using different tractometry, segmentation, or metrics\n",
    "\n",
    "Want:\n",
    "\n",
    "- a distance metric that is similar to correlation\n",
    "\n",
    "  - bounded between 0 and 1\n",
    "  \n",
    "  - 0 signifies streamlines are infinitely far apart\n",
    "  \n",
    "  - 1 signifies same streamline\n",
    "\n",
    "Consider: \n",
    "\n",
    "- MDF between every pair\n",
    "\n",
    "- Threshold distance $\\theta$\n",
    "\n",
    "  - If distance is greater than threshold then streamlines are considered infinitely far apart (not part of the same subbundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MDF (Minimum average Direct-Flip)\n",
    "\n",
    "https://dipy.org/documentation/1.2.0./reference/dipy.segment/#bundles-distances-mdf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mdfs = {}\n",
    "is_mdfs = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    mdfs[subject] = {}\n",
    "    is_mdfs[subject] = {}\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        mdfs[subject][bundle_name] = {}\n",
    "        is_mdfs[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_mdf.npy')\n",
    "\n",
    "            if compare_test_retest:\n",
    "                if op.isfile(f_name):\n",
    "                    mdfs[subject][bundle_name][ses] = np.load(f_name)\n",
    "                    print(name, subject, bundle_name, 'mdf', 'loading', f_name)\n",
    "                \n",
    "                f_name = op.join(target_dir,'adjacency_is_mdf.npy')\n",
    "\n",
    "                if op.isfile(f_name):\n",
    "                    is_mdfs[subject][bundle_name][ses] = np.load(f_name)\n",
    "                    print(name, subject, bundle_name, 'is_mdf', 'loading', f_name)\n",
    "            else:\n",
    "                loc = get_iloc(myafq, subject)            \n",
    "                tg_fname = get_tractogram_filename(myafq, bundle_name, loc)\n",
    "                tractogram = load_tractogram(tg_fname, 'same')\n",
    "                streamlines = tractogram.streamlines\n",
    "                affine = tractogram.affine\n",
    "                \n",
    "                if len(streamlines) == 0:\n",
    "                    print(dataset_name, subject, bundle_name, 'mdf', 'no streamlines')\n",
    "                    continue\n",
    "\n",
    "                fgarray = np.array(dts.set_number_of_points(streamlines, 100))\n",
    "            \n",
    "                tic = time.perf_counter()\n",
    "                mdf = pd.DataFrame(dts.bundles_distances_mdf(fgarray, fgarray))\n",
    "                mdfs[subject][bundle_name][ses] = mdf\n",
    "\n",
    "                # np.save(op.join(target_dir,'adjacency_mdf.npy'), mdf.to_numpy())\n",
    "\n",
    "                # inverse scaled mdf (is_mdf)\n",
    "\n",
    "                mdf_max = mdf.to_numpy().max()\n",
    "                is_mdf = (mdf_max - mdf)\n",
    "                is_mdf_max = is_mdf.to_numpy().max()\n",
    "                is_mdf = is_mdf / is_mdf_max\n",
    "                is_mdfs[subject][bundle_name][ses] = is_mdf\n",
    "                toc = time.perf_counter()\n",
    "                print(dataset_name, subject, bundle_name, f'{toc - tic:0.4f} seconds')\n",
    "\n",
    "                f_name = op.join(target_dir,'adjacency_is_mdf.npy')\n",
    "                np.save(f_name, is_mdf.to_numpy())\n",
    "                print(dataset_name, subject, bundle_name, 'is_mdf', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_mdfs = {}\n",
    "for subject in subjects:\n",
    "    is_mdfs[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        is_mdfs[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            f_name = op.join(target_dir,'adjacency_is_mdf.npy')\n",
    "            if op.isfile(f_name):\n",
    "                is_mdfs[subject][bundle_name][ses] = np.load(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Adjacencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\alpha$ FA + $\\beta$ MD "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "alphas = np.linspace(0,10,11)/10\n",
    "betas = np.linspace(10,0,11)/10\n",
    "\n",
    "fa_md_wts = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    fa_md_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        fa_md_wts[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:          \n",
    "            fa_md_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "\n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_fa_{int(beta*10)}_md.npy')\n",
    "\n",
    "                if compare_test_retest:\n",
    "                    fa_md_wts[subject][bundle_name][ses].append(np.load(f_name))\n",
    "                    print(name, subject, bundle_name, 'fa_md_wts', 'loading', f_name)\n",
    "                else:\n",
    "                    weighted = alpha * fa_corrs[subject][bundle_name][ses] + beta * md_corrs[subject][bundle_name][ses]\n",
    "                    fa_md_wts[subject][bundle_name][ses].append(weighted)\n",
    "                    np.save(f_name,  weighted.to_numpy())\n",
    "                    print(dataset_name, subject, bundle_name, 'fa_md_wts', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_md_wts = {}\n",
    "for subject in subjects:\n",
    "    fa_md_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        fa_md_wts[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            fa_md_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_fa_{int(beta*10)}_md.npy')\n",
    "                if op.isfile(f_name):\n",
    "                    fa_md_wts[subject][bundle_name][ses].append(np.load(f_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\alpha$ FA $R^2$ + $\\beta$ MDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "alphas = np.linspace(0,10,11)/10\n",
    "betas = np.linspace(10,0,11)/10\n",
    "\n",
    "far2_mdf_wts = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    far2_mdf_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        far2_mdf_wts[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            far2_mdf_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            if not ses in fa_r2s[subject][bundle_name] or not ses in is_mdfs[subject][bundle_name]:\n",
    "                print(dataset_name, subject, bundle_name, 'fa_r2_is_mdf_wts', 'no values')\n",
    "                continue\n",
    "\n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_fa_r2_{int(beta*10)}_is_mdf.npy')\n",
    "                \n",
    "                if compare_test_retest:\n",
    "                    far2_mdf_wts[subject][bundle_name][ses].append(np.load(f_name))\n",
    "                    print(name, subject, bundle_name, 'fa_r2_is_mdf_wts', 'loading', f_name)\n",
    "                else:\n",
    "                    wt_far2_mdf = alpha * fa_r2s[subject][bundle_name][ses] + beta * is_mdfs[subject][bundle_name][ses]\n",
    "                    far2_mdf_wts[subject][bundle_name][ses].append(wt_far2_mdf)\n",
    "                    \n",
    "                    np.save(f_name, wt_far2_mdf.to_numpy())\n",
    "                    print(dataset_name, subject, bundle_name, 'fa_r2_is_mdf_wts', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0,10,11)/10\n",
    "betas = np.linspace(10,0,11)/10\n",
    "\n",
    "far2_mdf_wts = {}\n",
    "for subject in subjects:\n",
    "    far2_mdf_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        far2_mdf_wts[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            far2_mdf_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_fa_r2_{int(beta*10)}_is_mdf.npy')\n",
    "                if op.isfile(f_name):\n",
    "                    far2_mdf_wts[subject][bundle_name][ses].append(np.load(f_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\alpha$  $\\mu$-Reference Warped FA $R^2$ + $\\beta$ MDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "alphas = np.linspace(0,10,11)/10\n",
    "betas = np.linspace(10,0,11)/10\n",
    "\n",
    "mean_warped_far2_mdf_wts = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    mean_warped_far2_mdf_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        mean_warped_far2_mdf_wts[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            mean_warped_far2_mdf_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            if not ses in mean_warped_fa_r2s[subject][bundle_name] or not ses in is_mdfs[subject][bundle_name]:\n",
    "                print(dataset_name, subject, bundle_name, 'ref_warped_fa_r2_is_mdf_wts', 'no values')\n",
    "                continue\n",
    "\n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_ref_warped_fa_r2_{int(beta*10)}_is_mdf.npy')\n",
    "\n",
    "                if compare_test_retest:\n",
    "                    mean_warped_far2_mdf_wts[subject][bundle_name][ses].append(np.load(f_name))\n",
    "                    print(name, subject, bundle_name, 'ref_warped_fa_r2_is_mdf_wts', 'loading', f_name)\n",
    "                else:\n",
    "                    wt_warpedfar2_mdf = alpha * mean_warped_fa_r2s[subject][bundle_name][ses] + beta * is_mdfs[subject][bundle_name][ses]\n",
    "                    mean_warped_far2_mdf_wts[subject][bundle_name][ses].append(wt_warpedfar2_mdf)\n",
    "\n",
    "                    np.save(f_name, wt_warpedfar2_mdf.to_numpy())\n",
    "                    print(dataset_name, subject, bundle_name, 'ref_warped_fa_r2_is_mdf_wts', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0,10,11)/10\n",
    "betas = np.linspace(10,0,11)/10\n",
    "\n",
    "mean_warped_far2_mdf_wts = {}\n",
    "for subject in subjects:\n",
    "    mean_warped_far2_mdf_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        mean_warped_far2_mdf_wts[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            mean_warped_far2_mdf_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_ref_warped_fa_r2_{int(beta*10)}_is_mdf.npy')\n",
    "                if op.isfile(f_name):\n",
    "                    mean_warped_far2_mdf_wts[subject][bundle_name][ses].append(np.load(f_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\alpha$ Pairwise Warped FA $R^2$ + $\\beta$ MDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "alphas = np.linspace(0,10,11)/10\n",
    "betas = np.linspace(10,0,11)/10\n",
    "\n",
    "pairwise_warped_far2_mdf_wts = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    pairwise_warped_far2_mdf_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        pairwise_warped_far2_mdf_wts[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            pairwise_warped_far2_mdf_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            if not ses in pairwise_warped_fa_r2s[subject][bundle_name] or not ses in is_mdfs[subject][bundle_name]:\n",
    "                print(dataset_name, subject, bundle_name, 'pairwisewarpedfar2_mdf_wts', 'no values')\n",
    "                continue\n",
    "\n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_pairwise_warped_fa_r2_{int(beta*10)}_is_mdf.npy')\n",
    "                \n",
    "                if compare_test_retest:\n",
    "                    pairwise_warped_far2_mdf_wts[subject][bundle_name][ses].append(np.load(f_name))\n",
    "                    print(name, subject, bundle_name, 'pairwisewarpedfar2_mdf_wts', 'loading', f_name)\n",
    "                else:\n",
    "                    wt_warpedfar2_mdf = alpha * pairwise_warped_fa_r2s[subject][bundle_name][ses] + beta * is_mdfs[subject][bundle_name][ses]\n",
    "                    pairwise_warped_far2_mdf_wts[subject][bundle_name][ses].append(wt_warpedfar2_mdf)\n",
    "\n",
    "                    np.save(f_name, wt_warpedfar2_mdf.to_numpy())\n",
    "                    print(dataset_name, subject, bundle_name, 'pairwisewarpedfar2_mdf_wts', 'saving', f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0,10,11)/10\n",
    "betas = np.linspace(10,0,11)/10\n",
    "\n",
    "pairwise_warped_far2_mdf_wts = {}\n",
    "for subject in subjects:\n",
    "    pairwise_warped_far2_mdf_wts[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        pairwise_warped_far2_mdf_wts[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            pairwise_warped_far2_mdf_wts[subject][bundle_name][ses] = []\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            for alpha, beta in zip(alphas, betas):\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_pairwise_warped_fa_r2_{int(beta*10)}_is_mdf.npy')\n",
    "                if op.isfile(f_name):\n",
    "                    pairwise_warped_far2_mdf_wts[subject][bundle_name][ses].append(np.load(f_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Matricies\n",
    "\n",
    "Once get streamline correlation matricies:\n",
    "\n",
    "- Begin with \"eye-ball comparison\" between FA and MD matrices\n",
    "\n",
    "- Then consider difference of adjacency matrices\n",
    "\n",
    "\n",
    "- <span style=\"color:red\">**Question: What is the 'correct' way compare these matricies?**</span>\n",
    "\n",
    "  - Check how much information is shared\n",
    "  \n",
    "    mutual information: $\\mathbb{I}(X,Y)$\n",
    "    \n",
    "  - Or alternatively, information only present in only one of the matricies\n",
    "  \n",
    "    i.e. sum of conditional information: $\\mathbb{H}(Y|X)+\\mathbb{H}(X|Y)$\n",
    "    \n",
    "      equivallently, cross entropy minus mutial information: $\\mathbb{H}(X,Y)-\\mathbb{I}(X,Y)$\n",
    "\n",
    "<span style=\"color:red\">**NOTE: we are assuming that streamlines are same (from same individual and same same tractography)**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are interested finite and symmetric matricies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  \"Eye-ball\" Absolute Difference\n",
    "\n",
    "This was a first pass, now not as informative"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            plt.figure()\n",
    "            plt.title(f'{name} {subject} {bundle_name} {ses} FA - MD adjacency')\n",
    "            del_corr = np.abs(fa_corrs[subject][bundle_name][ses]-md_corrs[subject][bundle_name][ses])\n",
    "            plt.imshow(del_corr, cmap='hot', interpolation='nearest')\n",
    "            plt.xlabel('streamline index')\n",
    "            plt.ylabel('streamline index')\n",
    "            plt.colorbar()\n",
    "            f_name = op.join(target_dir, f'adjacency_fa_md_diff.png')\n",
    "            print(f_name)\n",
    "            plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA\n",
    "\n",
    "Baseline FA hasn't been that useful, but have been using as starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in fa_corrs[subject][bundle_name]:\n",
    "                continue\n",
    "                \n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            plt.figure()\n",
    "            plt.title(f'{name} {subject} {bundle_name} {ses} FA adjacency')\n",
    "            plt.imshow(fa_corrs[subject][bundle_name][ses], cmap='hot', interpolation='nearest')\n",
    "            plt.xlabel('streamline index')\n",
    "            plt.ylabel('streamline index')\n",
    "            plt.colorbar()\n",
    "            f_name = op.join(target_dir, f'adjacency_fa.png')\n",
    "            print(f_name)\n",
    "            plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA $R^2$\n",
    "\n",
    "Baseline FA R2. This doesn't account for offsets in streamlines and other streamline alignment issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in fa_r2s[subject][bundle_name]:\n",
    "                continue\n",
    "\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            plt.figure()\n",
    "            plt.title(f'{name} {subject} {bundle_name} {ses} FA $R^2$ adjacency')\n",
    "            plt.imshow(fa_r2s[subject][bundle_name][ses], cmap='hot', interpolation='nearest')\n",
    "            plt.xlabel('streamline index')\n",
    "            plt.ylabel('streamline index')\n",
    "            plt.colorbar()\n",
    "            f_name = op.join(target_dir, f'adjacency_fa_r2.png')\n",
    "            print(f_name)\n",
    "            plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "\n",
    "            adjacency_test(fa_r2s[subject][bundle_name][ses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  $\\mu$-Reference  Warped FA $R^2$\n",
    "\n",
    "One of two warpings exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in mean_warped_fa_r2s[subject][bundle_name]:\n",
    "                continue\n",
    "                \n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            plt.figure()\n",
    "            plt.title(f'{name} {subject} {bundle_name} {ses} $\\mu$ Warped FA $R^2$ adjacency')\n",
    "            plt.imshow(mean_warped_fa_r2s[subject][bundle_name][ses], cmap='hot', interpolation='nearest')\n",
    "            plt.xlabel('streamline index')\n",
    "            plt.ylabel('streamline index')\n",
    "            plt.colorbar()\n",
    "            f_name = op.join(target_dir, f'adjacency_ref_warped_fa_r2.png')\n",
    "            print(f_name)\n",
    "            plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "\n",
    "            adjacency_test(mean_warped_fa_r2s[subject][bundle_name][ses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pairwise Warped FA $R^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in pairwise_warped_fa_r2s[subject][bundle_name]:\n",
    "                continue\n",
    "                \n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            plt.figure()\n",
    "            plt.title(f'{name} {subject} {bundle_name} {ses} Pairwise Warped FA $R^2$ adjacency')\n",
    "            plt.imshow(pairwise_warped_fa_r2s[subject][bundle_name][ses], cmap='hot', interpolation='nearest')\n",
    "            plt.xlabel('streamline index')\n",
    "            plt.ylabel('streamline index')\n",
    "            plt.colorbar()\n",
    "            f_name = op.join(target_dir, f'adjacency_pairwise_warped_fa_r2.png')\n",
    "            print(f_name)\n",
    "            plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "\n",
    "            adjacency_test(pairwise_warped_fa_r2s[subject][bundle_name][ses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MD\n",
    "\n",
    "Currently not exploiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in md_corrs[subject][bundle_name]:\n",
    "                continue\n",
    "                \n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            plt.figure()\n",
    "            plt.title(f'{name} {subject} {bundle_name} {ses} MD adjacency')\n",
    "            plt.imshow(md_corrs[subject][bundle_name][ses], cmap='hot', interpolation='nearest')\n",
    "            plt.xlabel('streamline index')\n",
    "            plt.ylabel('streamline index')\n",
    "            plt.colorbar()\n",
    "            f_name = op.join(target_dir, f'adjacency_md.png')\n",
    "            print(f_name)\n",
    "            plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "\n",
    "            adjacency_test(md_corrs[subject][bundle_name][ses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MDF\n",
    "\n",
    "Adds spatial structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            if not ses in is_mdfs[subject][bundle_name]:\n",
    "                continue\n",
    "                \n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            plt.figure()\n",
    "            plt.title(f'{name} {subject} {bundle_name} {ses} MDF adjacency')\n",
    "            plt.imshow(is_mdfs[subject][bundle_name][ses], cmap='hot', interpolation='nearest')\n",
    "            plt.xlabel('streamline index')\n",
    "            plt.ylabel('streamline index')\n",
    "            plt.colorbar()\n",
    "            f_name = op.join(target_dir, f'adjacency_is_mdf.png')\n",
    "            print(f_name)\n",
    "            plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "\n",
    "            adjacency_test(is_mdfs[subject][bundle_name][ses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\alpha$ FA $R^2$ + $\\beta$ MDF\n",
    "\n",
    "Initial weighted combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            if not ses in far2_mdf_wts[subject][bundle_name]:\n",
    "                continue\n",
    "\n",
    "            for far2_mdf_wt, alpha, beta in zip(far2_mdf_wts[subject][bundle_name][ses], alphas, betas):\n",
    "                plt.figure()\n",
    "                plt.title(f'{name} {subject} {bundle_name} {ses} FA $R^2$ + MDF adjacency')\n",
    "                plt.imshow(far2_mdf_wt, cmap='hot', interpolation='nearest')\n",
    "                plt.xlabel('streamline index')\n",
    "                plt.ylabel('streamline index')\n",
    "                plt.colorbar()\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_fa_r2_{int(beta*10)}_is_mdf.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()\n",
    "\n",
    "                adjacency_test(far2_mdf_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\alpha$  $\\mu$-Reference Warped FA $R^2$ + $\\beta$ MDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            if not ses in mean_warped_far2_mdf_wts[subject][bundle_name]:\n",
    "                continue\n",
    "                \n",
    "            for mean_warped_far2_mdf_wt, alpha, beta in zip(mean_warped_far2_mdf_wts[subject][bundle_name][ses], alphas, betas):\n",
    "                plt.figure()\n",
    "                plt.title(f'{name} {subject} {bundle_name} {ses} $\\mu$ Warped FA $R^2$ + MDF adjacency')\n",
    "                plt.imshow(mean_warped_far2_mdf_wt, cmap='hot', interpolation='nearest')\n",
    "                plt.xlabel('streamline index')\n",
    "                plt.ylabel('streamline index')\n",
    "                plt.colorbar()\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_ref_warped_fa_r2_{int(beta*10)}_is_mdf.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()\n",
    "\n",
    "                adjacency_test(mean_warped_far2_mdf_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\alpha$  Pairwise Warped FA $R^2$ + $\\beta$ MDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([''], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            target_dir = target_dirs[subject][bundle_name][ses]\n",
    "            \n",
    "            if not ses in pairwise_warped_far2_mdf_wts[subject][bundle_name]:\n",
    "                continue\n",
    "                \n",
    "            for pairwise_warped_far2_mdf_wt, alpha, beta in zip(pairwise_warped_far2_mdf_wts[subject][bundle_name][ses], alphas, betas):\n",
    "                plt.figure()\n",
    "                plt.title(f'{name} {subject} {bundle_name} {ses} Pairwise Warped FA $R^2$ + MDF adjacency')\n",
    "                plt.imshow(pairwise_warped_far2_mdf_wt, cmap='hot', interpolation='nearest')\n",
    "                plt.xlabel('streamline index')\n",
    "                plt.ylabel('streamline index')\n",
    "                plt.colorbar()\n",
    "                f_name = op.join(target_dir, f'adjacency_wt_{int(alpha*10)}_pairwise_warped_fa_r2_{int(beta*10)}_is_mdf.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()\n",
    "\n",
    "                adjacency_test(pairwise_warped_far2_mdf_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
