{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subbundles Part 3: Streamline Profiles\n",
    "\n",
    "**Subbundle** - a subgroup of streamlines with a set of common properties\n",
    "\n",
    "Part 3: Get streamline profiles for tissue properties `fa_values` and `md_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import time\n",
    "import os.path as op\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dipy.io.streamline import load_tractogram\n",
    "from dipy.stats.analysis import afq_profile, gaussian_weights\n",
    "from dipy.tracking.streamline import set_number_of_points, values_from_volume\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from AFQ import api\n",
    "import AFQ.data as afd\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlines (from Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFQ\n",
    "\n",
    "- Instantiate AFQ object: `myafq` for desired dataset\n",
    "\n",
    "- get `row` from `myafq` to interact with api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_test_retest = False\n",
    "\n",
    "test_retest_dir = 'HCP_test_retest'\n",
    "test_retest_sessions = ['test', 'retest']\n",
    "test_retest_names = ['HCP', 'HCP_retest']\n",
    "\n",
    "# dataset_name = 'HCP'\n",
    "dataset_name = 'HCP_retest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = get_subjects(dataset_name)\n",
    "subjects = get_subjects_small(dataset_name)\n",
    "# subjects = get_subjects_medium(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_test_retest:\n",
    "    sub_dir = test_retest_dir\n",
    "    \n",
    "    print('HCP')\n",
    "    myafq_test = get_afq('HCP')\n",
    "    display(myafq_test.data_frame)\n",
    "    \n",
    "    print('HCP_retest')\n",
    "    myafq_retest = get_afq('HCP_retest')\n",
    "    display(myafq_retest.data_frame)\n",
    "else:\n",
    "    sub_dir = dataset_name\n",
    "    \n",
    "    print(dataset_name)\n",
    "    myafq = get_afq(dataset_name)\n",
    "    display(myafq.data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if compare_test_retest:\n",
    "#     bundle_names = [*myafq_retest.bundle_dict]\n",
    "# else:\n",
    "#     bundle_names = [*myafq.bundle_dict]\n",
    "\n",
    "# bundle_names = ['SLF_L', 'SLF_R']\n",
    "# bundle_names = ['ARC_L', 'ARC_R', 'CST_L', 'CST_R', 'FP'] \n",
    "bundle_names = ['SLF_L', 'SLF_R', 'ARC_L', 'ARC_R', 'CST_L', 'CST_R', 'FP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "informational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_fnames = {}\n",
    "tractograms = {}\n",
    "streamlines = {}\n",
    "affines = {}\n",
    "\n",
    "for bundle_name in bundle_names:\n",
    "    if compare_test_retest:\n",
    "        make_dirs(myafq_retest, sub_dir, bundle_name, subjects)\n",
    "    else:\n",
    "        make_dirs(myafq, sub_dir, bundle_name, subjects)\n",
    "    \n",
    "for subject in subjects:\n",
    "    tg_fnames[subject] = {}\n",
    "    tractograms[subject] = {}\n",
    "    streamlines[subject] = {}\n",
    "    affines[subject] = {}\n",
    "    \n",
    "    if compare_test_retest:\n",
    "        loc_test  = get_iloc(myafq_test, subject)\n",
    "        loc_retest = get_iloc(myafq_retest, subject)\n",
    "    else:\n",
    "        loc = get_iloc(myafq, subject)\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        tg_fnames[subject][bundle_name] = {}\n",
    "        tractograms[subject][bundle_name] = {}\n",
    "        streamlines[subject][bundle_name] = {}\n",
    "        affines[subject][bundle_name] = {}\n",
    "\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions, [myafq_test, myafq_retest], [loc_test, loc_retest])\n",
    "        else:\n",
    "            iterables = zip([sub_dir], [dataset_name], [myafq], [loc])\n",
    "            \n",
    "        for name, ses, myafq, loc in iterables:\n",
    "            tg_fnames[subject][bundle_name][ses] = get_tractogram_filename(myafq, bundle_name, loc)\n",
    "            tractograms[subject][bundle_name][ses] = load_tractogram(tg_fnames[subject][bundle_name][ses], 'same')\n",
    "            streamlines[subject][bundle_name][ses] = tractograms[subject][bundle_name][ses].streamlines\n",
    "            affines[subject][bundle_name][ses] = tractograms[subject][bundle_name][ses].affine\n",
    "            \n",
    "tg_df = pd.DataFrame.from_dict(\n",
    "    {(i,j,k): [len(tractograms[i][j][k].streamlines), tractograms[i][j][k].affine, tg_fnames[i][j][k]] for i in tg_fnames.keys() for j in tg_fnames[i].keys() for k in tg_fnames[i][j].keys()}, \n",
    "    orient='index', \n",
    "    columns=['number of streamlines', 'affine', 'tratogram files']\n",
    ")\n",
    "\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(tg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Streamline Tract Profiles\n",
    "\n",
    "<span style=\"color:blue\">**TODO: Quantify *Stability* and *Robustness* of resulting tract profiles**</span>\n",
    "\n",
    "Verify that tract profiles are:\n",
    "\n",
    "- invariant to tractometry (same dataset, subject, and session)\n",
    "\n",
    "- similar across sessions (same dataset and subject)\n",
    "\n",
    "- similar across subjects (same dataset)\n",
    "\n",
    "- similar across datasets\n",
    "\n",
    "**These should align with published tolereances.**\n",
    "\n",
    "<span style=\"color:blue\">**TODO: find published sources**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamline Tract Profile Metrics\n",
    "\n",
    "Calculate Streamline Tract Profiles, using:\n",
    "\n",
    "- (DTI/DKI) Tissue Properties\n",
    "\n",
    "  - Other Tissue Properties\n",
    "\n",
    "- (Geometrically Constrained) Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (DTI/DKI) Tissue Properties:\n",
    "\n",
    "  - **[FA](https://en.wikipedia.org/wiki/Fractional_anisotropy) (*Fractional Anisotropy*)**\n",
    "  \n",
    "  - **MD (*Mean Diffusivity*)**\n",
    "  \n",
    "  - APM (*Anisotropic Power Map*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Geometrically Constrained) Distance:\n",
    "\n",
    "  - Euclidean\n",
    "  \n",
    "  - QuickBundle MDF (*Minimum Average Direct Flip*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other Tissue Properties:\n",
    "\n",
    "- [Relaxometry](https://radiopaedia.org/articles/relaxometry?lang=us)-based parameter\n",
    "\n",
    "- **T<sub>1</sub>/T<sub>2</sub> ratio** (**NOTE: May not exist for HARDI dataset**)\n",
    "\n",
    "- Quantitative T<sub>1</sub> (**NOTE: May not exist for HCP dataset**)\n",
    "    \n",
    "    \n",
    "- quantitative measures (T<sub>1</sub>, T<sub>2</sub>, T<sub>2</sub>*)\n",
    "  \n",
    "- semi-quantitative measures (T<sub>2</sub>-weighted/T<sub>1</sub>-weighted ratio (T<sub>2</sub>w/T<sub>1</sub>w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cortical Endpoints:\n",
    "\n",
    "See how close streamlines endpoints are to gray matter. **NOTE: @arokem: can determine from imaging information**\n",
    "\n",
    "- <span style=\"color:red\">**Question: how to use information?**<span>\n",
    "    \n",
    "    - as additional adjacency matricies, or\n",
    "    \n",
    "    - as input to topologically transform streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tissue Properties (Scalar Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostic information:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Streamline voxel length')\n",
    "\n",
    "streamline_len = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    streamline_len[subject] = {}\n",
    "    for bundle_name in bundle_names:\n",
    "        streamline_len[subject][bundle_name] = {}\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions)\n",
    "        else:\n",
    "            iterables = zip([sub_dir], [dataset_name])\n",
    "            \n",
    "        for name, ses in iterables:\n",
    "            streamline_len[subject][bundle_name][ses] = str(set(len(streamline) for streamline in streamlines[subject][bundle_name][ses]))\n",
    "\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(pd.DataFrame.from_dict(\n",
    "        {(i,j,k): streamline_len[i][j][k] for i in streamline_len.keys() for j in streamline_len[i].keys() for k in streamline_len[i][j].keys()}, \n",
    "        orient='index', \n",
    "        columns=['streamline lengths']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get scalar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Scalars')\n",
    "\n",
    "if compare_test_retest:\n",
    "    print('test', myafq_test.scalars)\n",
    "    print('retest', myafq_retest.scalars)\n",
    "else:\n",
    "    print(myafq.scalars)\n",
    "\n",
    "scalars = ['dti_fa']\n",
    "\n",
    "scalar_files = {}\n",
    "scalar_data = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    scalar_files[subject] = {}\n",
    "    scalar_data[subject] = {}\n",
    "\n",
    "    if compare_test_retest:\n",
    "        loc_test  = get_iloc(myafq_test, subject)\n",
    "        loc_retest = get_iloc(myafq_retest, subject)\n",
    "        \n",
    "        scalar_files[subject]['test'] = {}\n",
    "        scalar_files[subject]['retest'] = {}\n",
    "        \n",
    "        scalar_data[subject]['test'] = []\n",
    "        scalar_data[subject]['retest'] = []\n",
    "        \n",
    "        iterables = zip(test_retest_names, test_retest_sessions, [myafq_test, myafq_retest], [loc_test, loc_retest])\n",
    "    else:\n",
    "        loc = get_iloc(myafq, subject)\n",
    "        \n",
    "        scalar_files[subject][dataset_name] = {}\n",
    "        \n",
    "        scalar_data[subject][dataset_name] = []\n",
    "\n",
    "        iterables = zip([sub_dir], [dataset_name], [myafq], [loc])\n",
    "\n",
    "    for name, ses, myafq, loc in iterables:\n",
    "        for scalar in scalars:    \n",
    "            scalar_file = get_scalar_filename(myafq, scalar, loc)\n",
    "            scalar_files[subject][ses][scalar] = scalar_file\n",
    "            scalar_data[subject][ses].append(nib.load(scalar_file).get_fdata())\n",
    "\n",
    "scalars_df = pd.DataFrame.from_dict(\n",
    "    {(i,j,k): scalar_files[i][j][k] for i in scalar_files.keys() for j in scalar_files[i].keys() for k in scalar_files[i][j].keys()}, \n",
    "    orient='index', \n",
    "    columns=['scalar files']\n",
    ")\n",
    "\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(scalars_df)\n",
    "    \n",
    "os.makedirs(op.join('subbundles', dataset_name), exist_ok=True)\n",
    "f_name = op.join('subbundles', dataset_name, f'scalar_files.csv')\n",
    "print(f_name)\n",
    "scalars_df.to_csv(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**TODO: `anisotropic_power_map`**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamline Profiles\n",
    "\n",
    "Calculate tissue properties per streamline\n",
    "\n",
    "For reference:\n",
    "- https://github.com/dipy/dipy/blob/master/dipy/tracking/streamline.py#L668\n",
    "\n",
    "  - https://github.com/dipy/dipy/blob/master/dipy/stats/analysis.py#L221"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamline Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">NOTE: By default sampling `100` points from each streamline</span>\n",
    "\n",
    "- The choice of `n_points` by convenction, however want to ensure it is greater than minimum number in `streamlines`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "use_weighted_means = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original streamline profiles. Shows that the mean is not best fit, and possiblity that streamline profiles are\n",
    "\n",
    "- random (the grouping streamlines for bundle is arbitrary)\n",
    "\n",
    "- offset (the bundle is a single entity, but streamlines are shifted)\n",
    "\n",
    "- subbundles (the bundle has two or more subbundles)\n",
    "\n",
    "or some combination thereof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load from file instead of recalculating\n",
    "for subject in subjects:\n",
    "\n",
    "    if compare_test_retest:\n",
    "        loc_test  = get_iloc(myafq_test, subject)\n",
    "        loc_retest = get_iloc(myafq_retest, subject)\n",
    "    else:\n",
    "        loc = get_iloc(myafq, subject)\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions, [myafq_test, myafq_retest], [loc_test, loc_retest])\n",
    "        else:\n",
    "            iterables = zip([sub_dir], [dataset_name], [myafq], [loc])\n",
    "            \n",
    "        for name, ses, myafq, loc in iterables:\n",
    "            print(name, subject, bundle_name, ses)\n",
    "            fgarray = set_number_of_points(streamlines[subject][bundle_name][ses], n_points)\n",
    "            \n",
    "            if len(fgarray) == 0:\n",
    "                print(f'No streamlines for {name} {subject} {bundle_name} {ses}')\n",
    "                continue\n",
    "\n",
    "            for scalar_name, data in zip(scalars, scalar_data[subject][ses]):\n",
    "                truncated_name = scalar_name.split('_')[-1]\n",
    "                target_dir = get_dir_name(myafq, sub_dir, bundle_name, loc)\n",
    "                \n",
    "                values = np.array(values_from_volume(data, fgarray, affines[subject][bundle_name][ses]))\n",
    "#                 print(values)\n",
    "                print(values.shape)\n",
    "#                 print(len(values)==len(streamlines[subject][bundle_name][ses]))\n",
    "\n",
    "                if not compare_test_retest:\n",
    "                    f_name = op.join(target_dir, f'streamline_profile_{truncated_name}.npy')\n",
    "                    print(f_name)\n",
    "                    np.save(f_name, values)\n",
    "\n",
    "                if use_weighted_means:\n",
    "                    mean_values = afq_profile(\n",
    "                            data,\n",
    "                            streamlines[subject][bundle_name][ses],\n",
    "                            affines[subject][bundle_name][ses],\n",
    "                            weights=gaussian_weights(streamlines[subject][bundle_name][ses])\n",
    "                    )\n",
    "                else:\n",
    "                    mean_values = np.mean(values, axis=0)\n",
    "                    \n",
    "                if not compare_test_retest:\n",
    "                    reference_name = 'mean'\n",
    "                    \n",
    "                    if use_weighted_means:\n",
    "                        reference_name = 'weighted_mean'\n",
    "                        \n",
    "                    f_name = op.join(target_dir, f'streamline_profile_{reference_name}_{truncated_name}.npy')\n",
    "                    print(f_name)\n",
    "                    np.save(f_name, values)\n",
    "\n",
    "                plt.figure()\n",
    "                plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} profiles\\n streamline count:{len(tractograms[subject][bundle_name][ses].streamlines)}')\n",
    "                plt.plot(values.T, c='tab:blue', alpha=0.1)\n",
    "                plt.plot(mean_values.T, c='black', label='bundle mean ($\\mu$)')\n",
    "                plt.xlabel('node index')\n",
    "                plt.ylabel(f'{scalar_name} values')\n",
    "                plt.legend()\n",
    "                f_name = op.join(target_dir, f'streamline_{truncated_name}_profile.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()\n",
    "\n",
    "                fig = plt.figure()\n",
    "                plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} heatmap\\n streamline count:{len(tractograms[subject][bundle_name][ses].streamlines)}')\n",
    "                im = plt.imshow(values.T, cmap='hot', interpolation='nearest')\n",
    "                plt.xlabel('streamline index')\n",
    "                plt.ylabel('node index')\n",
    "                add_colorbar(im)\n",
    "                f_name = op.join(target_dir, f'streamline_{truncated_name}_heatmap.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aligned Streamline Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">NOTE: Alignment Problem</span>\n",
    "\n",
    "Streamlines do not have the same length\n",
    "\n",
    "Streamlines do not necessarily begin and end in same regions\n",
    "\n",
    "Streamlines may not terminate in or near gray matter\n",
    "\n",
    "- Some of the above concerns may be addressed downstream when clustering by adding additional metrics:\n",
    "\n",
    "  - Incorporate geometric distance\n",
    "  \n",
    "  - Incorporate streamline profiles for different streamline alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison (see Diffusion profile realignment (dpr)):\n",
    "\n",
    "https://github.com/samuelstjean/dpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dynamic Time Warping (DTW)\n",
    "\n",
    "<span style=\"color:blue\">**TODO: add quartiles**</span>\n",
    "\n",
    "<span style=\"color:red\">**NOTE: Reference: raw mean**</span>\n",
    "\n",
    "- Alternative references includ weighted average (afq_profile), centriod (QuickBundle), ...\n",
    "\n",
    "<span style=\"color:red\">**NOTE: Multivaluedness: to convert to single value; chioce: grabs the last value in sequence**</span>\n",
    "\n",
    " - Concerns over principled approach to resolve multivaluedness and reduce to single valued mapping\n",
    " \n",
    "   - Looking for deterministic, informed and reason for choices\n",
    "   \n",
    " - Approach\n",
    " \n",
    "   - for a given reference tissue profile: find the corresponding index to streamline profile index(es)\n",
    "   \n",
    "     - if multivalued: then _choose_ one of: first, last; min, max; average: mean, mode, median; wieghted average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\mu$-Reference Warped Streamlines"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# where elements change values\n",
    "print(path[:,1][:-1] != path[:,1][1:])\n",
    "\n",
    "# get indices where elements change values\n",
    "print(np.where(path[:,1][:-1] != path[:,1][1:]))\n",
    "\n",
    "# use fancy indexing to find tuples where values change\n",
    "print(path[np.where(path[:,1][:-1] != path[:,1][1:])])\n",
    "\n",
    "# select only the x indicies\n",
    "print(path[np.where(path[:,1][:-1] != path[:,1][1:]),0])\n",
    "\n",
    "# select array\n",
    "print(path[np.where(path[:,1][:-1] != path[:,1][1:]),0][0])\n",
    "\n",
    "# check length\n",
    "print(len(path[np.where(path[:,1][:-1] != path[:,1][1:]),0][0]))\n",
    "\n",
    "# add last index\n",
    "print(np.append(path[np.where(path[:,1][:-1] != path[:,1][1:]),0][0], len(values.T)))\n",
    "\n",
    "# get the tissues property values at these indicies\n",
    "print(values[np.append(path[np.where(path[:,1][:-1] != path[:,1][1:]),0][0], len(values.T))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_warp_map = True\n",
    "show_baseline = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load from file instead of recalculating\n",
    "for subject in subjects:\n",
    "    if compare_test_retest:\n",
    "        loc_test  = get_iloc(myafq_test, subject)\n",
    "        loc_retest = get_iloc(myafq_retest, subject)\n",
    "    else:\n",
    "        loc = get_iloc(myafq, subject)\n",
    "        \n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions, [myafq_test, myafq_retest], [loc_test, loc_retest])\n",
    "        else:\n",
    "            iterables = zip([sub_dir], [dataset_name], [myafq], [loc])\n",
    "            \n",
    "        for name, ses, myafq, loc in iterables:\n",
    "            print(name, subject, bundle_name, ses)\n",
    "            target_dir = get_dir_name(myafq, sub_dir, bundle_name, loc)\n",
    "            fgarray = set_number_of_points(streamlines[subject][bundle_name][ses], n_points)\n",
    "            \n",
    "            if len(fgarray) == 0:\n",
    "                print(f'No streamlines for {name} {subject} {bundle_name} {ses}')\n",
    "                continue\n",
    "            \n",
    "            for scalar_name, data in zip(scalars, scalar_data[subject][ses]):\n",
    "                truncated_name = scalar_name.split('_')[-1]\n",
    "                values = np.array(values_from_volume(data, fgarray, affines[subject][bundle_name][ses]))\n",
    "                \n",
    "                if use_weighted_means:\n",
    "                    mean_values = afq_profile(\n",
    "                            data,\n",
    "                            streamlines[subject][bundle_name][ses],\n",
    "                            affines[subject][bundle_name][ses],\n",
    "                            weights=gaussian_weights(streamlines[subject][bundle_name][ses])\n",
    "                    )\n",
    "                else:\n",
    "                    mean_values = np.mean(values, axis=0)\n",
    "                    \n",
    "                if show_warp_map:\n",
    "                    plt.figure()\n",
    "                    plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} mean ($\\mu$)-reference warping map')\n",
    "                    for value in values:\n",
    "                        plt.plot(*zip(*fastdtw(value, mean_values)[1]), c='tab:blue')\n",
    "                    plt.xlabel('input node index')\n",
    "                    plt.ylabel('output node index')\n",
    "                    f_name = op.join(target_dir, f'{truncated_name}_warp_map.png')\n",
    "                    print(f_name)\n",
    "                    plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                    plt.show()\n",
    "\n",
    "                tic = time.perf_counter()\n",
    "                dtw_values = []\n",
    "\n",
    "                for value in values:\n",
    "                    dist, path = fastdtw(value, mean_values)\n",
    "\n",
    "                    path = np.array(path)\n",
    "\n",
    "                    dtw_values.append(value[np.append(path[np.where(path[:,1][:-1] != path[:,1][1:]),0][0], len(values.T)-1)])\n",
    "\n",
    "                dtw_values = np.array(dtw_values)\n",
    "                toc = time.perf_counter()\n",
    "                print(f'dtw calculation {toc - tic:0.4f} seconds')\n",
    "                print(dtw_values.shape)\n",
    "                \n",
    "                if not compare_test_retest:\n",
    "                    f_name = op.join(target_dir, f'streamline_profile_ref_warped_{truncated_name}.npy')\n",
    "                    print(f_name)\n",
    "                    np.save(f_name, dtw_values)\n",
    "\n",
    "                # cacluate warped bundle profile\n",
    "                if use_weighted_means:\n",
    "                    # TODO\n",
    "                    print('weighed warped mean not implemented!')\n",
    "                    continue\n",
    "                else:\n",
    "                    dtw_mean_values = np.mean(dtw_values, axis=0)\n",
    "                \n",
    "                if not compare_test_retest:\n",
    "                    reference_name = 'mean'\n",
    "                    \n",
    "                    if use_weighted_means:\n",
    "                        reference_name = 'weighted_mean'\n",
    "                        \n",
    "                    f_name = op.join(target_dir, f'streamline_profile_ref_warped_{reference_name}_{truncated_name}.npy')\n",
    "                    print(f_name)\n",
    "                    np.save(f_name, values)\n",
    "\n",
    "                # show original streamline profiles corresponding to the warp\n",
    "                #  duplicates plots from above, but useful so don't have to scroll \n",
    "                #  or if only interested in running and saving warps\n",
    "                if show_baseline:\n",
    "                    plt.figure()\n",
    "                    plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} streamline profiles')\n",
    "                    plt.plot(values.T, c='tab:blue', alpha=0.1)\n",
    "                    plt.plot(mean_values.T, c='black', label='bundle mean ($\\mu$)')\n",
    "                    plt.xlabel('node index')\n",
    "                    plt.ylabel(f'{scalar_name} values')\n",
    "                    plt.legend()\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.figure(figsize=(10,2))\n",
    "                    plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} heatmap')\n",
    "                    im = plt.imshow(values.T, cmap='hot', interpolation='nearest')\n",
    "                    plt.xlabel('streamline index')\n",
    "                    plt.ylabel('node index')\n",
    "                    add_colorbar(im)\n",
    "                    plt.show()\n",
    "\n",
    "                plt.figure()\n",
    "                plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} mean ($\\mu$)-reference warped streamline profiles')\n",
    "                plt.plot(dtw_values.T, c='tab:blue', alpha=0.1)\n",
    "                plt.plot(mean_values.T, c='black', label='bundle mean ($\\mu$)')\n",
    "                plt.plot(dtw_mean_values.T, c='black', label='warped bundle mean ($\\mu^{\\prime}$)', linestyle='dashed')\n",
    "                plt.xlabel('node index')\n",
    "                plt.ylabel(f'{scalar_name} values')\n",
    "                plt.legend()\n",
    "                f_name = op.join(target_dir, f'streamline_{truncated_name}_warp_profile.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure()\n",
    "                plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} mean ($\\mu$)-reference warped heatmap')\n",
    "                im = plt.imshow(dtw_values.T, cmap='hot', interpolation='nearest')\n",
    "                plt.xlabel('streamline index')\n",
    "                plt.ylabel('node index')\n",
    "                add_colorbar(im)\n",
    "                f_name = op.join(target_dir, f'streamline_{truncated_name}_warp_heatmap.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pairwise Warped Streamlines\n",
    "\n",
    "Warp each streamline to each other creates NxN matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean_vaules (n_points,)\n",
    "dtw_mean_values (n_points,)\n",
    "\n",
    "values (n_streamlines, n_points)\n",
    "exemplar_dtw_values (n_streamlines, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load from file instead of recalculating\n",
    "for subject in subjects:\n",
    "    if compare_test_retest:\n",
    "        loc_test  = get_iloc(myafq_test, subject)\n",
    "        loc_retest = get_iloc(myafq_retest, subject)\n",
    "    else:\n",
    "        loc = get_iloc(myafq, subject)\n",
    "\n",
    "    for bundle_name in bundle_names:\n",
    "        if compare_test_retest:\n",
    "            iterables = zip(test_retest_names, test_retest_sessions, [myafq_test, myafq_retest], [loc_test, loc_retest])\n",
    "        else:\n",
    "            iterables = zip([sub_dir], [dataset_name], [myafq], [loc])\n",
    "            \n",
    "        for name, ses, myafq, loc in iterables:\n",
    "            print(name, subject, bundle_name, ses)\n",
    "            target_dir = get_dir_name(myafq, sub_dir, bundle_name, loc)\n",
    "            fgarray = set_number_of_points(streamlines[subject][bundle_name][ses], n_points)\n",
    "            \n",
    "            if len(fgarray) == 0:\n",
    "                print(f'No streamlines for {name} {subject} {bundle_name} {ses}')\n",
    "                continue\n",
    "\n",
    "            for scalar_name, data in zip(scalars, scalar_data[subject][ses]):\n",
    "                truncated_name = scalar_name.split('_')[-1]\n",
    "                values = np.array(values_from_volume(data, fgarray, affines[subject][bundle_name][ses]))\n",
    "                \n",
    "                mean_values = np.mean(values, axis=0)\n",
    "\n",
    "                tic = time.perf_counter()\n",
    "                \n",
    "                dtw_values = np.zeros((values.shape[0], values.shape[0], values.shape[1]))\n",
    "                \n",
    "                for i, a in enumerate(values):\n",
    "                    for j, b in enumerate(values):\n",
    "                        _, path = fastdtw(a,b)\n",
    "                        path = np.array(path)\n",
    "                        dtw_value = a[np.append(path[np.where(path[:,1][:-1] != path[:,1][1:]),0][0], len(values.T)-1)]\n",
    "                        dtw_values[i,j] = dtw_value\n",
    "                \n",
    "                toc = time.perf_counter()\n",
    "                print(f'dtw calculation {toc - tic:0.4f} seconds')\n",
    "                print(dtw_values.shape)\n",
    "                \n",
    "                if not compare_test_retest:\n",
    "                    f_name = op.join(target_dir, f'streamline_profile_pairwise_warped_{truncated_name}.npy')\n",
    "                    print(f_name)\n",
    "                    np.save(f_name, dtw_values)\n",
    "\n",
    "                x, y = np.meshgrid(np.arange(dtw_values.shape[0]),np.arange(dtw_values.shape[1]))\n",
    "                \n",
    "                show_all_n_points = True\n",
    "                \n",
    "                # this show the full volume with all interior points\n",
    "                # illustrative (to get context for surface plots)\n",
    "                # it is computationally intensive, and not really necessary\n",
    "                if show_all_n_points:\n",
    "                    tic = time.perf_counter()\n",
    "\n",
    "                    fig = plt.figure()\n",
    "                    fig.suptitle(f'{name} {subject} {bundle_name} {scalar_name} {ses} pairwise warped streamline profiles wireframes')\n",
    "                    ax=fig.add_subplot(111,projection='3d')\n",
    "                    for i in range(dtw_values.shape[2]):\n",
    "                        ax.plot_wireframe(x, y, dtw_values[:,:,i])\n",
    "    #                     ax.plot_surface(x, y, dtw_values[:,:,i])\n",
    "                    ax.set_xlabel('streamline index')\n",
    "                    ax.set_ylabel('streamline index')\n",
    "                    ax.set_zlabel(f'{scalar_name} values')\n",
    "                    f_name = op.join(target_dir, f'streamline_{truncated_name}_pairwise_warp_profile_full.png')\n",
    "                    print(f_name)\n",
    "                    plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                    plt.show()\n",
    "                    toc = time.perf_counter()\n",
    "                    print(f'plot {toc - tic:0.4f} seconds')\n",
    "            \n",
    "                tic = time.perf_counter()\n",
    "        \n",
    "                # what really want to do is find external surfaces (min and max)\n",
    "                # TODO: how to create a wireframe of suface connecting min and max plane\n",
    "                # TODO: downsample no need to show every combination\n",
    "                fig = plt.figure()\n",
    "                fig.suptitle(f'{name} {subject} {bundle_name} {scalar_name} {ses} pairwise warped streamline profiles min-max wireframes')\n",
    "                ax=fig.add_subplot(111,projection='3d')\n",
    "                ax.plot_wireframe(x, y, np.amax(dtw_values, axis=2))\n",
    "                ax.plot_wireframe(x, y, np.amin(dtw_values, axis=2))\n",
    "                ax.set_xlabel('streamline index')\n",
    "                ax.set_ylabel('streamline index')\n",
    "                ax.set_zlabel(f'{scalar_name} values')\n",
    "                f_name = op.join(target_dir, f'streamline_{truncated_name}_pairwise_warp_profile.png')\n",
    "                print(f_name)\n",
    "                plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                plt.show()\n",
    "                \n",
    "                toc = time.perf_counter()\n",
    "                print(f'plot {toc - tic:0.4f} seconds')\n",
    "                            \n",
    "                show_exemplar = True\n",
    "                \n",
    "                # this should output a profile and heatmap that warp one streamline to another \n",
    "                # (as opposed to the mean as done above)\n",
    "                if show_exemplar:\n",
    "                    example = np.random.choice(dtw_values.shape[0])\n",
    "                    \n",
    "                    print(f'selecting streamline {example} from {name} {subject} {bundle_name} {scalar_name} {ses}')\n",
    "                    exemplar_dtw_values = dtw_values[example]\n",
    "                    dtw_mean_values = np.mean(exemplar_dtw_values, axis=0)\n",
    "                                        \n",
    "                    if show_warp_map:\n",
    "                        # show how each streamline warps to the sampled streamline based on tissue property\n",
    "                        plt.figure()\n",
    "                        plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} pairwise reference warping map for streamline {example}')\n",
    "                        for value in values:\n",
    "                            plt.plot(*zip(*fastdtw(value.T, exemplar_dtw_values[example].T)[1]), c='tab:blue')\n",
    "                        plt.plot(*zip(*fastdtw(values[example].T, exemplar_dtw_values[example].T)[1]), c='k', label=f'streamline {example}')\n",
    "                        plt.xlabel('input node index')\n",
    "                        plt.ylabel('output node index')\n",
    "                        plt.legend()\n",
    "                        f_name = op.join(target_dir, f'{truncated_name}_exemplar_pairwise_warp_map.png')\n",
    "                        print(f_name)\n",
    "                        plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                        plt.show()\n",
    "\n",
    "                    # show the streamline with the mean and the warped mean\n",
    "                    # to get sense of how warping to this streamline effects the meam\n",
    "                    plt.figure()\n",
    "                    plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} target pairwise streamline {example}')\n",
    "                    plt.plot(mean_values.T, c='k', label='bundle mean ($\\mu$)')\n",
    "                    plt.plot(dtw_mean_values.T, c='k', linestyle='dashed', label='exemplar mean ($\\mu^{\\prime}$)')\n",
    "                    # these are same as maps directly to itself\n",
    "#                     plt.plot(exemplar_dtw_values[example].T,  c='tab:blue', label='exemplar dtw values')\n",
    "                    plt.plot(values[example].T, c='tab:blue', label='exemplar values')\n",
    "                    plt.xlabel('node index')\n",
    "                    plt.ylabel(f'{scalar_name} values')\n",
    "                    plt.legend()\n",
    "                    f_name = op.join(target_dir, f'streamline_{truncated_name}_exemplar_pairwise_warp.png')\n",
    "                    print(f_name)\n",
    "                    plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # show all the streamlines before warping to sampled streamline\n",
    "                    plt.figure()\n",
    "                    plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} streamline profiles {example}')\n",
    "                    plt.plot(values.T, c='tab:blue', alpha=0.1)\n",
    "                    plt.plot(mean_values.T, c='k', label='bundle mean ($\\mu$)')\n",
    "                    plt.plot(dtw_mean_values.T, c='k', linestyle='dashed', label='exemplar mean ($\\mu^{\\prime}$)')\n",
    "                    plt.xlabel('node index')\n",
    "                    plt.ylabel(f'{scalar_name} values')\n",
    "                    plt.legend()\n",
    "                    f_name = op.join(target_dir, f'streamline_{truncated_name}_exemplar_pairwise_profile.png')\n",
    "                    print(f_name)\n",
    "                    plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                    plt.show()\n",
    "\n",
    "                    # show all the streamlines after warping to sampled streamline\n",
    "                    plt.figure()\n",
    "                    plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} pairwise warped streamline profiles for streamline {example}')\n",
    "                    plt.plot(exemplar_dtw_values.T, c='tab:blue', alpha=0.1)\n",
    "                    plt.plot(mean_values.T, c='black', label='bundle mean ($\\mu$)')\n",
    "                    plt.plot(dtw_mean_values.T, c='black', label='exemplar mean ($\\mu^{\\prime}$)', linestyle='dashed')\n",
    "                    plt.xlabel('node index')\n",
    "                    plt.ylabel(f'{scalar_name} values')\n",
    "                    plt.legend()\n",
    "                    f_name = op.join(target_dir, f'streamline_{truncated_name}_exemplar_pairwise_warp_profile.png')\n",
    "                    print(f_name)\n",
    "                    plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                    plt.show()\n",
    "\n",
    "                    # show the effect of warping on the tissue property values\n",
    "                    plt.figure()\n",
    "                    plt.title(f'{name} {subject} {bundle_name} {scalar_name} {ses} pairwise warped heatmap for streamline {example}')\n",
    "                    im = plt.imshow(exemplar_dtw_values.T, cmap='hot', interpolation='nearest')\n",
    "                    plt.xlabel('streamline index')\n",
    "                    plt.ylabel('node index')\n",
    "                    add_colorbar(im)\n",
    "                    f_name = op.join(target_dir, f'streamline_{truncated_name}_exemplar_pairwise_warp_heatmap.png')\n",
    "                    print(f_name)\n",
    "                    plt.savefig(f_name, bbox_inches = \"tight\")\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">**TODO: Other Warps**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
