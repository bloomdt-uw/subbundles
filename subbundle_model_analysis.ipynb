{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subbundle Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reload imports for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: To see more detailed information set `logging.DEBUG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subbundle_model_analysis_utils import fetch_model_data, make_bundle_dict, ClusterType\n",
    "from identify_subbundles import *\n",
    "from visualizations import *\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('subbundle')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Assumes clustering models exist for each `{subject}` and `{session_name}` for each `{bundle_name}`. \n",
    "\n",
    "For each `{expirement_name}` -- consisting of feature selection and embedding, choice of clustring algorithm and corresponding model hyperparameters -- results are saved to:\n",
    "\n",
    "> s3://hcp-subbundle/{expirement_name}/{session_name}/{bundle_name}/{subject}/{n_clusters}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "Constants from pyAFQ and HCP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of pyAFQ bundle identifers\n",
    "BUNDLE_NAMES = [\n",
    "    'ATR_L', 'ATR_R',\n",
    "    'CGC_L', 'CGC_R',\n",
    "    'CST_L', 'CST_R',\n",
    "    'IFO_L', 'IFO_R',\n",
    "    'ILF_L', 'ILF_R',\n",
    "    'SLF_L', 'SLF_R',\n",
    "    'ARC_L', 'ARC_R',\n",
    "    'UNC_L', 'UNC_R',\n",
    "    'FA', 'FP'\n",
    "]\n",
    "\n",
    "# list of HCP test-retest subject identifiers\n",
    "SUBJECTS = [\n",
    "    '103818', '105923', '111312', '114823', '115320',\n",
    "    '122317', '125525', '130518', '135528', '137128',\n",
    "    '139839', '143325', '144226', '146129', '149337',\n",
    "    '149741', '151526', '158035', '169343', '172332',\n",
    "    '175439', '177746', '185442', '187547', '192439',\n",
    "    '194140', '195041', '200109', '200614', '204521',\n",
    "    '250427', '287248', '341834', '433839', '562345',\n",
    "    '599671', '601127', '627549', '660951', # '662551', \n",
    "    '783462', '859671', '861456', '877168', '917255'\n",
    "]\n",
    "\n",
    "# list of HCP test and retest session names\n",
    "SESSION_NAMES = ['HCP_1200', 'HCP_Retest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment and Model Metadata\n",
    "\n",
    "dictionary of information passed to helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**:\n",
    "- One bundle at a time\n",
    "- Experiment was run for only `ARC_L`, `ARC_R`, `SLF_L`, and `SLF_R`\n",
    "- Experiment was run for 2-4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUNDLE_NAME = 'SLF_L'\n",
    "print('bundle', BUNDLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Filtering removes clusters for some subjects. Concerns over impact.\n",
    "\n",
    "Less than ideal that the two bundles have completely different subjects that exhibit this effect.\n",
    "\n",
    "**TODO**: Automaticaly detect and remove subjects.\n",
    "\n",
    "```\n",
    "for d in */ ; do echo \"$d\" ; rsync --dry-run --verbose --recursive --existing --ignore-existing --delete-after $d/HCP_1200/ $d/HCP_Retest/ | grep clean | awk '{print $NF}'; done\n",
    "```\n",
    "\n",
    "```\n",
    "for d in */ ; do echo \"$d\" ; rsync --dry-run --verbose --recursive --existing --ignore-existing --delete-after $d/HCP_Retest/ $d/HCP_1200/ | grep clean | awk '{print $NF}'; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Current strategy: excluding subjects.** \n",
    "\n",
    "Effect: Reduces $N$ subjects reported.\n",
    "\n",
    "**Alternative strategies:**\n",
    "- Adjust filter threshold to be less agressive\n",
    "- Skip cluster.\n",
    "  This will cause list of clusters to be shorter and mislabel clusters, as result profiles to be calculated incorrectly\n",
    "- No op cluster.\n",
    "  Add empty placeholder list or list of all zeros, profiles will likely be calculated incorrectly\n",
    "- Move or replace model to $N-1$ clusters.\n",
    "  Time and heavy code impact. Reduces $N$ subjects reported.\n",
    "- Skip model.\n",
    "- Skip subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess effect of alternative strategies could look at smaller subset of subjects that present issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering removes one of the clusters for these subjects\n",
    "\n",
    "For now do not include them in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_subjects = []\n",
    "\n",
    "if BUNDLE_NAME == 'SLF_L':\n",
    "    excluded_subjects = ['125525', '195041', '200109', '599671']\n",
    "elif BUNDLE_NAME == 'SLF_R':\n",
    "    excluded_subjects = ['122317', '137128', '149741', '187547', '660951']\n",
    "elif BUNDLE_NAME == 'ARC_L':\n",
    "    excluded_subjects = ['287248']\n",
    "elif BUNDLE_NAME == 'ARC_R':\n",
    "    excluded_subjects = ['135528', '144226', '917255']\n",
    "\n",
    "print('excluded subjects:', excluded_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_excluded_subjects = True\n",
    "inspect_excluded_subjects = False\n",
    "\n",
    "if remove_excluded_subjects:\n",
    "    print('removing excluded subjects')\n",
    "    for subject in excluded_subjects:\n",
    "        SUBJECTS.remove(subject)\n",
    "elif inspect_excluded_subjects:\n",
    "    print('inspecting excluded subjects')\n",
    "    SUBJECTS = excluded_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import random\n",
    "\n",
    "metadata = {}\n",
    "\n",
    "# experiment\n",
    "metadata['experiment_name'] = 'MASE_FA_Sklearn_KMeans'\n",
    "\n",
    "metadata['experiment_output_dir'] = join('subbundles', metadata['experiment_name'])\n",
    "\n",
    "metadata['experiment_bundles'] = [BUNDLE_NAME]\n",
    "\n",
    "metadata['experiment_subjects'] = SUBJECTS \n",
    "print('subjects', metadata['experiment_subjects'])\n",
    "\n",
    "metadata['experiment_sessions'] = SESSION_NAMES\n",
    "metadata['experiment_test_session'] = metadata['experiment_sessions'][0]\n",
    "metadata['experiment_retest_session'] = metadata['experiment_sessions'][1]\n",
    "\n",
    "metadata['experiment_range_n_clusters'] = [2, 3, 4] \n",
    "metadata['experiment_bundle_dict'] = make_bundle_dict(metadata)\n",
    "\n",
    "# model\n",
    "metadata['model_name'] = 'mase_kmeans_fa_r2_is_mdf'\n",
    "metadata['model_scalars'] = [Scalars.DTI_FA]\n",
    "\n",
    "# analysis\n",
    "metadata['n_points'] = 100\n",
    "metadata['algorithm'] = Algorithm.MUNKRES\n",
    "metadata['bundle_name'] = BUNDLE_NAME\n",
    "metadata['n_clusters'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove local analysis artifacts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clean(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = fetch_model_data(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify a `consensus_subject` and appropriately relabel clusters\n",
    "\n",
    "   Generates the following local artifacts:\n",
    "    \n",
    "   `{expirement_name}/{bundle_name}/{subject}/{session}/{n_clusters}/`\n",
    "   \n",
    "  - `{target}_{algorithm}_labels.npy` \n",
    "\n",
    "     cluster labels for `subject` using `target` as consensus subject `algorithm`\n",
    "\n",
    "  - `{subject}_{bundle_name}_{cluster_id}_MNI.trk` \n",
    "\n",
    "     cleaned cluster tractogram in MNI space\n",
    "\n",
    "     **NOTE:** `cluster_id` is the original cluster label from the model.\n",
    "\n",
    "  - `{subject}_{bundle_name}_{cluster_id}_MNI_density_map.nii.gz` \n",
    "\n",
    "     density map for the cleaned cluster tractogram in MNI space used to calculate weighted dice coefficient.\n",
    "     \n",
    "     _optionally_ only generated when using `Algorithm.MAXDICE` or `Algorithm.MUNKRES`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build `cluster_info` dict:\n",
    "- `cluster_info[n_clusters]`\n",
    "  - `cluster_info[n_clusters]['consensus_subject']`\n",
    "  - `cluster_info[n_clusters][session_name]`\n",
    "     - `cluster_info[n_clusters][session_name]['centroids']`\n",
    "     - `cluster_info[n_clusters][session_name]['tractograms_filenames']`\n",
    "     - `cluster_info[n_clusters][session_name]['tractograms']`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: some clusters are removed as result of filtering and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving some computational time by using previous consensus subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consensus_subjects = {}\n",
    "consensus_subjects[2] = {}\n",
    "consensus_subjects[3] = {}\n",
    "consensus_subjects[4] = {}\n",
    "\n",
    "if BUNDLE_NAME == 'SLF_L':\n",
    "    consensus_subjects[2]['consensus_subject'] = '187547'\n",
    "    consensus_subjects[3]['consensus_subject'] = '660951'\n",
    "    consensus_subjects[4]['consensus_subject'] = '139839'\n",
    "elif BUNDLE_NAME == 'SLF_R':\n",
    "    consensus_subjects[2]['consensus_subject'] = '250427'\n",
    "    consensus_subjects[3]['consensus_subject'] = '783462'\n",
    "    consensus_subjects[4]['consensus_subject'] = '172332'\n",
    "elif BUNDLE_NAME == 'ARC_L':\n",
    "    consensus_subjects[2]['consensus_subject'] = '859671'\n",
    "elif BUNDLE_NAME == 'ARC_R':\n",
    "    consensus_subjects[2]['consensus_subject'] = '115320'\n",
    "    \n",
    "print('consensus subjects:', consensus_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_info = get_cluster_info(metadata, consensus_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relabel retest clusters based on `consensus_subject`\n",
    "\n",
    "- labels are aligned across test-retest for consensus_subject before relabeling retest subjects\n",
    "\n",
    "   `{expirement_name}/{bundle_name}/{consensus_subject}/HCP_Retest/{cluster_number}/consensus_mdf_labels.npy`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "match_retest_clusters(metadata, cluster_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_dice_coeffs = get_bundle_dice_coefficients(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dice_coeffs = {}\n",
    "\n",
    "for n_clusters in metadata['experiment_range_n_clusters']:\n",
    "    cluster_dice_coeffs[n_clusters] = get_cluster_dice_coefficients(\n",
    "        metadata,\n",
    "        cluster_info,\n",
    "        n_clusters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_afq_profiles = get_bundle_afq_profiles(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_afq_profiles = {}\n",
    "\n",
    "for n_clusters in metadata['experiment_range_n_clusters']:    \n",
    "     cluster_afq_profiles[n_clusters] = get_cluster_afq_profiles(\n",
    "        metadata, \n",
    "        n_clusters, \n",
    "        cluster_info[n_clusters]['consensus_subject']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Visualizations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CORONAL = dict(\n",
    "    eye=dict(x=0., y=1., z=0.),\n",
    "    up=dict(x=-1., y=0., z=1.)\n",
    ")\n",
    "\n",
    "RIGHT_SAGITTAL = dict(\n",
    "    eye=dict(x=1., y=0., z=0.),\n",
    "    up=dict(x=-1., y=0., z=1.)\n",
    ")\n",
    "\n",
    "LEFT_SAGITTAL =dict(\n",
    "    eye=dict(x=-1., y=0., z=0.),\n",
    "    up=dict(x=-1., y=0., z=1.)\n",
    ")\n",
    "\n",
    "RIGHT_HORIZONTAL = dict(\n",
    "    eye=dict(x=0., y=0., z=1.),\n",
    "    up=dict(x=-1., y=0., z=0.)\n",
    ")\n",
    "\n",
    "LEFT_HORIZONTAL = dict(\n",
    "    eye=dict(x=0., y=0., z=1.),\n",
    "    up=dict(x=-1., y=0., z=1.)\n",
    ")\n",
    "\n",
    "\n",
    "if BUNDLE_NAME.endswith('L'):\n",
    "    PLOTLY_CAMERAS = [CORONAL, LEFT_SAGITTAL, LEFT_HORIZONTAL]\n",
    "else:\n",
    "    PLOTLY_CAMERAS = [CORONAL, RIGHT_SAGITTAL, RIGHT_HORIZONTAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** interactive plotly has been crashing, using ploty to generate pngs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def display_anatomy_figures(anatomy_figures):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from io import BytesIO\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    \n",
    "    f, ax = plt.subplots(len(metadata['experiment_sessions']), len(PLOTLY_CAMERAS))\n",
    "\n",
    "    session_id = 0\n",
    "    for session_name in metadata['experiment_sessions']:\n",
    "        fig = anatomy_figures[session_name]\n",
    "        fig.update_layout(showlegend=False)\n",
    "        fig.update_layout(margin=dict(l=0,r=0,t=0,b=0))\n",
    "        \n",
    "        camera_id = 0\n",
    "        for camera in PLOTLY_CAMERAS:    \n",
    "            fig.update_layout(scene_camera=camera)\n",
    "            png = fig.to_image(format='png', width=200, height=200)\n",
    "            im = np.array(Image.open(BytesIO(png)))\n",
    "            ax[session_id, camera_id].imshow(im)\n",
    "            ax[session_id, camera_id].set_axis_off()\n",
    "            camera_id += 1\n",
    "        session_id += 1\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def display_anatomy_figures(anatomy_figures):\n",
    "    from IPython.display import Image\n",
    "\n",
    "    for session_name in metadata['experiment_sessions']:\n",
    "        fig = anatomy_figures[session_name]\n",
    "        fig.update_layout(showlegend=False)\n",
    "        fig.update_layout(margin=dict(l=0,r=0,t=0,b=0))\n",
    "        \n",
    "        for camera in PLOTLY_CAMERAS:    \n",
    "            fig.update_layout(scene_camera=camera)\n",
    "            png = fig.to_image(format='png', width=250, height=200)\n",
    "            im = Image(png)\n",
    "            display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot bundle FA profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_population_bundle_profiles(\n",
    "    metadata,\n",
    "    bundle_afq_profiles[metadata['model_scalars'][0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bundle streamline count statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bundle_streamline_stats(metadata, model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bundle weighted dice coefficient statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bundle_dice_coeff_stats(metadata, bundle_dice_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bundle FA profile test-retest reliability statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bundle_profile_reliability_stats(\n",
    "    metadata,\n",
    "    bundle_afq_profiles[metadata['model_scalars'][0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_population_cluster_profile(\n",
    "    metadata, \n",
    "    cluster_afq_profiles[metadata['n_clusters']][metadata['model_scalars'][0]],\n",
    "    'DTI FA',\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster streamline count statistics\n",
    "\n",
    "**NOTE** can check cluster `model` or `filtered`. here just looking at `clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc = get_cluster_streamline_counts(metadata, model_data)\n",
    "    \n",
    "display_cluster_streamline_count_stats(metadata, csc, metadata['n_clusters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster weighted dice cofficient test-retest reliability\n",
    "\n",
    "**NOTE**: \n",
    "- Dice was higher with DTI and without the two stage cleaning. Could check model bundles, filtered bundles, and not just clean. \n",
    "- Also there is a large varation between max and min dice which is effecting the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bdcs = get_bundle_dice_coeff_stats(\n",
    "    bundle_dice_coeffs\n",
    ")\n",
    "\n",
    "display_cluster_dice_coef(\n",
    "    metadata,\n",
    "    cluster_dice_coeffs,\n",
    "    metadata['n_clusters'],\n",
    "    bdcs.loc['mean'][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster fa profile test-retest reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpr = get_cluster_profile_reliability(\n",
    "    metadata,\n",
    "    cluster_afq_profiles\n",
    ")\n",
    "    \n",
    "bprs = get_bundle_profile_reliability_stats(\n",
    "    metadata,\n",
    "    bundle_afq_profiles[metadata['model_scalars'][0]]\n",
    ")\n",
    "\n",
    "display_cluster_profile_reliability_stats(\n",
    "    metadata,\n",
    "    cpr,\n",
    "    metadata['n_clusters'],\n",
    "    bprs.loc['mean'][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consensus Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anatomical plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_anatomy_figures = get_consensus_bundle_anatomy_figures(\n",
    "    metadata, \n",
    "    model_data, \n",
    "    cluster_info, \n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display_anatomy_figures(bundle_anatomy_figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bundle streamline counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc = get_consensus_streamline_counts(metadata, model_data, cluster_info)\n",
    "\n",
    "display(\n",
    "    csc.loc[csc['n_clusters'] == metadata['n_clusters']].style.set_caption(f\"{metadata['bundle_name']} consensus subject streamline counts\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bundle weighted dice coefficient test-retest reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdc = get_bundle_dice_coeff(bundle_dice_coeffs, cluster_info[n_clusters]['consensus_subject'])\n",
    "\n",
    "display(\n",
    "    cbdc.style.set_caption(f\"{metadata['bundle_name']} consensus subject weighted dice coefficient\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbpr = get_consensus_bundle_profile_reliability(\n",
    "    metadata,\n",
    "    bundle_afq_profiles[metadata['model_scalars'][0]],\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")\n",
    "\n",
    "display(\n",
    "    cbpr.style.set_caption(f\"{metadata['bundle_name']} consensus subject DTI FA pearson r\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### adjacencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_adjacencies(\n",
    "    metadata,\n",
    "    model_data,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model artifacts: silhouette scores and pair plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_model_artifacts(\n",
    "    metadata,\n",
    "    model_data,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot filtered artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_filtered_artifacts(\n",
    "    metadata,\n",
    "    model_data,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FA profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall using deterministic DTI prior; this is deterministic CSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jointly plot streamline and bundle FA profiles for `subject` and `session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_streamline_bundle_profile(\n",
    "    metadata,\n",
    "    model_data,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot cluster FA profiles for `subject`, `session`, and `n_clusters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_cluster_profiles(\n",
    "    metadata,\n",
    "    model_data,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cluster streamlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** investigate why getting extra line in `bundle_to_tgram` plots"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def add_bundles(t1, t2):\n",
    "    import nibabel as nib\n",
    "    \n",
    "    data_per_streamline = {k: (list(t1.data_per_streamline[k])\n",
    "                               + list(t2.data_per_streamline[k]))\n",
    "                           for k in t2.data_per_streamline.keys()}\n",
    "    return nib.streamlines.Tractogram(\n",
    "        list(t1.streamlines) + list(t2.streamlines),\n",
    "        data_per_streamline,\n",
    "        affine_to_rasmm=t2.affine_to_rasmm)\n",
    "\n",
    "\n",
    "def bundles_to_tgram(bundles, bundle_dict, reference):\n",
    "    import nibabel as nib\n",
    "    from dipy.io.stateful_tractogram import StatefulTractogram, Space\n",
    "    \n",
    "    tgram = nib.streamlines.Tractogram([], {'bundle': []})\n",
    "    print(len(tgram))\n",
    "    for b in bundles:\n",
    "        this_sl = bundles[b].streamlines\n",
    "        print(len(this_sl))\n",
    "        this_tgram = nib.streamlines.Tractogram(\n",
    "            this_sl,\n",
    "            data_per_streamline={\n",
    "                'bundle': (len(this_sl)\n",
    "                           * [bundle_dict[b]['uid']])},\n",
    "                affine_to_rasmm=reference.affine)\n",
    "        tgram = add_bundles(tgram, this_tgram)\n",
    "        print(len(tgram))\n",
    "    return StatefulTractogram(tgram.streamlines, reference, Space.VOX,\n",
    "                              data_per_streamline=tgram.data_per_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anatomical plot of subjects cluster tractograms in single visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_cluster_figs = get_clean_consensus_cluster_tractograms(\n",
    "    metadata,\n",
    "    model_data,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display_anatomy_figures(consensus_cluster_figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster streamline counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_cluster_streamline_counts(\n",
    "    metadata,\n",
    "    model_data,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consensus cluster weighed bundle dice coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_cluster_dice_coef(\n",
    "    metadata,\n",
    "    cluster_info,\n",
    "    cluster_dice_coeffs,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consensus cluster FA corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_consensus_cluster_profile_reliability(\n",
    "    metadata,\n",
    "    cluster_info,\n",
    "    cluster_afq_profiles,\n",
    "    metadata['n_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show (MNI space) results for individuals and group:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### centriods\n",
    "\n",
    "- Quality control check, much easier to view each cluster as centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_optionally_ view consensus subject centroids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display_consensus_centroids(metadata, cluster_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*optionally* choose a subject to investigate"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display_subject_centriods(metadata, cluster_info, subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_optionally_ view centroids for original model clusters, labeled by streamline count. \n",
    "\n",
    "- Compare to labeling algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display_streamline_count_centroids(metadata, cluster_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view labeling algoritm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** plotly may crash running this\n",
    "- display_centroids generates multiple plotly \n",
    "    - best to run `visualize_tractogram` one at a time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display_centroids(metadata, cluster_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid_figures(metadata, cluster_info, n_clusters, save_sfts=False):\n",
    "    centroid_figs = {}\n",
    "\n",
    "    for session_name in metadata['experiment_sessions']:\n",
    "        mni_centroids = get_relabeled_centroids(\n",
    "            metadata,\n",
    "            n_clusters,\n",
    "            session_name,\n",
    "            cluster_info[n_clusters]['consensus_subject']\n",
    "        )\n",
    "\n",
    "        mni_sft = convert_centroids(\n",
    "            n_clusters,\n",
    "            session_name,\n",
    "            mni_centroids,\n",
    "            metadata['experiment_bundle_dict'],\n",
    "            save_sfts\n",
    "        )\n",
    "\n",
    "        centroid_figs[session_name] = visualize_tractogram(\n",
    "            mni_sft,\n",
    "            metadata['experiment_bundle_dict']\n",
    "        )\n",
    "        \n",
    "    return centroid_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_figs = get_centroid_figures(\n",
    "    metadata,\n",
    "    cluster_info,\n",
    "    metadata['n_clusters'],\n",
    "    True # temporary saving for ariel\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display_anatomy_figures(centroid_figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose $K$ \n",
    "\n",
    "From the `metadata['experiment_range_n_clusters']` choose the model that is most reliabile across sessions.\n",
    "\n",
    "Based on the scalar profiles for subjects' clusters\n",
    "\n",
    "average RMSE - root mean squared difference per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K, data = find_K(metadata, bundle_afq_profiles, cluster_afq_profiles)\n",
    "print(metadata['bundle_name'], metadata['algorithm'], 'Choosing n_cluster', K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_choose_k_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary saving for ariel\n",
    "import numpy as np\n",
    "profile_tensor = get_bundle_profile_tensor(\n",
    "    metadata,\n",
    "    bundle_afq_profiles[metadata['model_scalars'][0]]\n",
    ")\n",
    "np.save(f'output/{BUNDLE_NAME}_bundle_tensor.npy', profile_tensor)\n",
    "print(profile_tensor.shape)\n",
    "\n",
    "\n",
    "for n_clusters in metadata['experiment_range_n_clusters']:  \n",
    "    profile_tensor = get_cluster_profile_tensor(\n",
    "        metadata,\n",
    "        cluster_afq_profiles[n_clusters][metadata['model_scalars'][0]],\n",
    "        n_clusters\n",
    "    )\n",
    "    \n",
    "    np.save(f'output/{BUNDLE_NAME}_n_clusters_{n_clusters}_tensor.npy', profile_tensor)\n",
    "    print(profile_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calinski-Harabasz criterion clustering evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_f = get_pseudo_f(metadata, cluster_afq_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary saving for ariel\n",
    "np.save(f'output/{BUNDLE_NAME}_n_clusters_2_pseudo_f.npy', pseudo_f[2][metadata['model_scalars'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
